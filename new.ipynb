{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\milen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\milen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Média do MSE: 9.146935874181615\n",
      "Random Forest - Média do R²: -0.02339024755003896\n",
      "Gradient Boosting - Média do MSE: 10.252676417009145\n",
      "Gradient Boosting - Média do R²: -0.2633344220592247\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Carregar dados\n",
    "data = pd.read_csv('C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima.csv')\n",
    "\n",
    "# Convertendo 'Data' para datetime e calculando a diferença diária do 'Preco_Dolar'\n",
    "data['Data'] = pd.to_datetime(data['Data'])\n",
    "data['Dif_Preco_Dolar'] = data['Preco_Dolar'].Dif()\n",
    "data = data.dropna()\n",
    "\n",
    "# Tratamento de outliers (exemplo simples)\n",
    "# Substitua com seu método preferido de tratamento de outliers\n",
    "# data = seu_metodo_de_tratamento_de_outliers(data)\n",
    "\n",
    "# Separando os dados para treino, validação e teste\n",
    "cutoff_date = pd.to_datetime(\"2023-01-01\")\n",
    "train_val_data = data[data['Data'] < cutoff_date]\n",
    "test_data = data[data['Data'] >= cutoff_date]\n",
    "\n",
    "# Preparação dos dados\n",
    "features_train_val = train_val_data.drop(['Preco_Dolar', 'Dif_Preco_Dolar', 'Data'], axis=1)\n",
    "target_train_val = train_val_data['Dif_Preco_Dolar']\n",
    "\n",
    "# Dividindo treino e validação\n",
    "features_train, features_val, target_train, target_val = train_test_split(features_train_val, target_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajuste fino dos hiperparâmetros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Melhores hiperparâmetros:\", best_params)\n",
    "\n",
    "rf_best = RandomForestRegressor(**best_params, random_state=42)\n",
    "rf_best.fit(features_train, target_train)\n",
    "\n",
    "# Avaliação usando Gradient Boosting para comparação\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "gb.fit(features_train, target_train)\n",
    "\n",
    "# Avaliação do modelo\n",
    "window_size = 30\n",
    "mse_values_rf, r2_values_rf = [], []\n",
    "mse_values_gb, r2_values_gb = [], []\n",
    "all_predictions_rf, all_predictions_gb = [], []\n",
    "all_actual_values = []\n",
    "\n",
    "for start in range(0, len(test_data) - window_size + 1):\n",
    "    end = start + window_size\n",
    "    test_subset = test_data.iloc[start:end]\n",
    "    features_test = test_subset.drop(['Preco_Dolar', 'Dif_Preco_Dolar', 'Data'], axis=1)\n",
    "    target_test = test_subset['Dif_Preco_Dolar']\n",
    "\n",
    "    prediction_rf = rf_best.predict(features_test)\n",
    "    prediction_gb = gb.predict(features_test)\n",
    "\n",
    "    mse_values_rf.append(mean_squared_error(target_test, prediction_rf))\n",
    "    r2_values_rf.append(r2_score(target_test, prediction_rf))\n",
    "\n",
    "    mse_values_gb.append(mean_squared_error(target_test, prediction_gb))\n",
    "    r2_values_gb.append(r2_score(target_test, prediction_gb))\n",
    "\n",
    "    all_predictions_rf.extend(prediction_rf)\n",
    "    all_predictions_gb.extend(prediction_gb)\n",
    "    all_actual_values.extend(target_test)\n",
    "\n",
    "# Exibindo os resultados para Random Forest\n",
    "print(\"Random Forest - Média do MSE:\", np.mean(mse_values_rf))\n",
    "print(\"Random Forest - Média do R²:\", np.mean(r2_values_rf))\n",
    "\n",
    "# Exibindo os resultados para Gradient Boosting\n",
    "print(\"Gradient Boosting - Média do MSE:\", np.mean(mse_values_gb))\n",
    "print(\"Gradient Boosting - Média do R²:\", np.mean(r2_values_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 9.595039206728583\n",
      "MAE: 2.260820458170779\n",
      "R^2: 0.18082554425127229\n",
      "           Data  Valor_Real  Valor_Previsto\n",
      "5524 2020-01-02       -3.67       -0.407749\n",
      "5525 2020-01-03       -1.07       -0.872377\n",
      "5526 2020-01-06       -5.45       -0.020286\n",
      "5527 2020-01-07       -0.83        0.177764\n",
      "5528 2020-01-08       -1.42        0.415451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\AppData\\Local\\Temp\\ipykernel_24468\\3619221553.py:38: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
      "C:\\Users\\milen\\AppData\\Local\\Temp\\ipykernel_24468\\3619221553.py:39: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar =('C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima.csv')\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "data_dolar.fillna(0, inplace=True)\n",
    "# Converter a coluna 'Data' para datetime e ordenar os dados\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "data_dolar = data_dolar.sort_values(by='Data')\n",
    "\n",
    "# Calcular a diferença diária do 'Preco_Dolar'\n",
    "data_dolar['Dif_Preco_Dolar'] = data_dolar['Preco_Dolar'].Dif()\n",
    "\n",
    "# Remover a primeira linha\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Dividir os dados em treino, teste e validação\n",
    "# Filtrar os dados para treino e teste\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2020-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data', 'Preco_Dolar', 'Dif_Preco_Dolar'])\n",
    "\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data', 'Preco_Dolar', 'Dif_Preco_Dolar'])\n",
    "\n",
    "# O restante do código para tratamento de dados não numéricos, treinamento e avaliação do modelo permanece o mesmo.\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)\n",
    "#Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Treinar o modelo de regressão linear\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular as métricas de desempenho\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "\n",
    "# Criar um DataFrame com as datas, valores reais e previstos\n",
    "resultados = pd.DataFrame()\n",
    "resultados['Data'] = test_data['Data']\n",
    "resultados['Valor_Real'] = y_test\n",
    "resultados['Valor_Previsto'] = y_pred\n",
    "\n",
    "# Exibir os primeiros registros para verificar\n",
    "print(resultados.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 12.404340249641168\n",
      "MAE: 2.6074201833883848\n",
      "R^2: -0.05901794187522991\n",
      "           Data  Valor_Real  Valor_Previsto\n",
      "5524 2020-01-02       -3.67       -6.098756\n",
      "5525 2020-01-03       -1.07       -1.238335\n",
      "5526 2020-01-06       -5.45       -9.077853\n",
      "5527 2020-01-07       -0.83       -2.184520\n",
      "5528 2020-01-08       -1.42       -2.827011\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar =('C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_atualizado.csv')\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "data_dolar.fillna(0, inplace=True)\n",
    "# Converter a coluna 'Data' para datetime e ordenar os dados\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "data_dolar = data_dolar.sort_values(by='Data')\n",
    "\n",
    "# Calcular a diferença diária do 'Preco_Dolar'\n",
    "#data_dolar['Dif_Preco_Dolar'] = data_dolar['Preco_Dolar'].Dif()\n",
    "\n",
    "# Remover a primeira linha\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Dividir os dados em treino, teste e validação\n",
    "# Filtrar os dados para treino e teste\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2020-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data', 'Dif_Preco_Dolar'])\n",
    "\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data', 'Dif_Preco_Dolar'])\n",
    "\n",
    "# O restante do código para tratamento de dados não numéricos, treinamento e avaliação do modelo permanece o mesmo.\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)\n",
    "#Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Treinar o modelo de regressão linear\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular as métricas de desempenho\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "\n",
    "# Criar um DataFrame com as datas, valores reais e previstos\n",
    "resultados = pd.DataFrame()\n",
    "resultados['Data'] = test_data['Data']\n",
    "resultados['Valor_Real'] = y_test\n",
    "resultados['Valor_Previsto'] = y_pred\n",
    "\n",
    "# Exibir os primeiros registros para verificar\n",
    "print(resultados.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.9983441660626964\n",
      "MAE: 0.9991717400240543\n",
      "R^2: nan\n",
      "           Data  Valor_Real  Valor_Previsto\n",
      "4231 2020-03-04       -1.95       -0.950828\n",
      "           Data  Dif_Preco_Dolar  Valor_Previsto\n",
      "5122 2023-10-30            -1.83       -0.352933\n",
      "5123 2023-10-31             5.45        0.127794\n",
      "5124 2023-11-01            -3.32        2.335962\n",
      "5125 2023-11-03             7.86       39.668988\n",
      "5126 2023-11-06             2.20        0.981174\n",
      "5127 2023-11-07             0.43        0.755369\n",
      "5128 2023-11-08             2.86       14.612960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R^2 score is not well-defined with less than two samples.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar =('C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_cme.csv')\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "\n",
    "# Separar os últimos 10 dias de dados\n",
    "ultimos_10_dias = data_dolar.tail(7)\n",
    "data_dolar = data_dolar.iloc[:-7]\n",
    "\n",
    "# Continuar com o pré-processamento como antes...\n",
    "\n",
    "# Remover a primeira linha\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Função para remover outliers\n",
    "def remove_outliers(df, column_names):\n",
    "    for column in column_names:\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Aplicar a remoção de outliers\n",
    "numeric_columns = data_dolar.select_dtypes(include=[np.number]).columns.tolist()\n",
    "data_dolar = remove_outliers(data_dolar, numeric_columns)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2020-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data','Dif_Preco_Dolar','Preco_Real', 'Dif_Preco_Real','Preco_Dolar'])\n",
    "\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data','Dif_Preco_Dolar','Preco_Real', 'Dif_Preco_Real','Preco_Dolar'])\n",
    "\n",
    "# Calcular a média para as colunas e substituir NaN pela média\n",
    "mean_values_train = X_train.mean()\n",
    "X_train.fillna(mean_values_train, inplace=True)\n",
    "\n",
    "mean_values_test = X_test.mean()\n",
    "X_test.fillna(mean_values_test, inplace=True)\n",
    "\n",
    "# Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Treinar o modelo de regressão linear\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular as métricas de desempenho\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "\n",
    "# Criar um DataFrame com as datas, valores reais e previstos\n",
    "resultados = pd.DataFrame()\n",
    "resultados['Data'] = test_data['Data']\n",
    "resultados['Valor_Real'] = y_test\n",
    "resultados['Valor_Previsto'] = y_pred\n",
    "\n",
    "# Exibir os primeiros registros para verificar\n",
    "print(resultados.head())\n",
    "\n",
    "# Preparar dados dos últimos 10 dias para a previsão\n",
    "X_ultimos_10_dias = ultimos_10_dias.drop(columns=['Data','Dif_Preco_Dolar','Preco_Real', 'Dif_Preco_Real','Preco_Dolar'])\n",
    "X_ultimos_10_dias.fillna(mean_values_train, inplace=True)\n",
    "\n",
    "# Prever os valores para 'ultimos_10_dias'\n",
    "y_ultimos_10_dias_pred = model.predict(X_ultimos_10_dias)\n",
    "\n",
    "# Comparar as previsões com os valores reais\n",
    "ultimos_10_dias['Valor_Previsto'] = y_ultimos_10_dias_pred\n",
    "print(ultimos_10_dias[['Data', 'Dif_Preco_Dolar', 'Valor_Previsto']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O MELHOR MELHOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.9275394800923684\n",
      "MAE: 0.8391132780534716\n",
      "R^2: 0.3277792654327595\n",
      "           Data  Valor_Real  Valor_Previsto\n",
      "6391 2023-06-26        0.45        1.403968\n",
      "6392 2023-06-27        0.10       -1.003845\n",
      "6395 2023-06-30        1.30        2.252853\n",
      "6396 2023-07-03       -0.63       -0.094444\n",
      "6399 2023-07-06       -1.34       -2.022010\n",
      "6404 2023-07-13        1.85        0.812661\n",
      "6407 2023-07-18       -0.39        0.288551\n",
      "6410 2023-07-21        2.79        1.164435\n",
      "6411 2023-07-24        2.62        1.912676\n",
      "6412 2023-07-25       -0.15       -1.257611\n",
      "6413 2023-07-26        0.39        1.037881\n",
      "6414 2023-07-27       -0.67        0.535776\n",
      "6418 2023-08-02        0.03       -0.073454\n",
      "6425 2023-08-11       -1.40        0.302492\n",
      "6428 2023-08-16        0.19        0.523376\n",
      "6430 2023-08-18        0.25       -0.571402\n",
      "6431 2023-08-21        0.32       -0.066038\n",
      "6432 2023-08-22        1.15        1.526829\n",
      "6436 2023-08-28        1.29       -0.063466\n",
      "6441 2023-09-04        0.78        0.829645\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar =('C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_atualizado.csv')\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime e ordenar os dados\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "# data_dolar = data_dolar.sort_values(by='Data')\n",
    "\n",
    "# Remover a primeira linha\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Função para remover outliers\n",
    "def remove_outliers(df, column_names):\n",
    "    for column in column_names:\n",
    "        Q1 = df[column].quantile(0.20)\n",
    "        Q3 = df[column].quantile(0.80)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 0.4 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Aplicar a remoção de outliers\n",
    "numeric_columns = data_dolar.select_dtypes(include=[np.number]).columns.tolist()\n",
    "data_dolar = remove_outliers(data_dolar, numeric_columns)\n",
    "\n",
    "# Dividir os dados em treino, teste e validação\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2022-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2022-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data','Pontos', 'Dif_Preco_Dolar','TaxaSelic','OperacoesSeleic','UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data','Pontos', 'Dif_Preco_Dolar','TaxaSelic','OperacoesSeleic','UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "# Calcular a média para as colunas e substituir NaN pela média\n",
    "mean_values_train = X_train.mean()\n",
    "X_train.fillna(mean_values_train, inplace=True)\n",
    "\n",
    "mean_values_test = X_test.mean()\n",
    "X_test.fillna(mean_values_test, inplace=True)\n",
    "\n",
    "# Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Treinar o modelo de regressão linear\n",
    "model = LinearRegression()\n",
    "#model = lgb.LGBMRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular as métricas de desempenho\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "\n",
    "# Criar um DataFrame com as datas, valores reais e previstos\n",
    "resultados = pd.DataFrame()\n",
    "resultados['Data'] = test_data['Data']\n",
    "resultados['Valor_Real'] = y_test\n",
    "resultados['Valor_Previsto'] = y_pred\n",
    "\n",
    "# Exibir os primeiros registros para verificar\n",
    "print(resultados.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... [seu código anterior permanece inalterado até o treinamento do modelo] ...\n",
    "\n",
    "# Definindo o tamanho da janela deslizante\n",
    "tamanho_da_janela = 5\n",
    "\n",
    "# Inicializando o DataFrame de resultados\n",
    "resultados = pd.DataFrame(columns=['Data', 'Valor_Real', 'Valor_Previsto'])\n",
    "\n",
    "# Fazendo previsões em uma janela deslizante\n",
    "for i in range(0, len(test_data), tamanho_da_janela):\n",
    "    # Selecionar os dados da janela atual\n",
    "    X_test_janela = X_test.iloc[i:i+tamanho_da_janela]\n",
    "    y_test_janela = y_test.iloc[i:i+tamanho_da_janela]\n",
    "    datas_janela = test_data['Data'].iloc[i:i+tamanho_da_janela]\n",
    "\n",
    "    # Prever os valores para a janela atual\n",
    "    y_pred_janela = model.predict(X_test_janela)\n",
    "\n",
    "    # Armazenar os resultados\n",
    "    janela_resultados = pd.DataFrame({\n",
    "        'Data': datas_janela,\n",
    "        'Valor_Real': y_test_janela,\n",
    "        'Valor_Previsto': y_pred_janela\n",
    "    })\n",
    "    resultados = resultados.append(janela_resultados, ignore_index=True)\n",
    "\n",
    "# Calcular as métricas de desempenho para todo o período de teste\n",
    "mse = mean_squared_error(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "mae = mean_absolute_error(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "r2 = r2_score(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "print(resultados.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3.1077767802435763\n",
      "MAE: 1.4787053674773167\n",
      "R^2: -1.2523159767585392\n",
      "           Data  Valor_Real  Valor_Previsto\n",
      "6391 2023-06-26        0.45        1.877941\n",
      "6392 2023-06-27        0.10        1.564456\n",
      "6395 2023-06-30        1.30        1.702488\n",
      "6396 2023-07-03       -0.63        1.720908\n",
      "6399 2023-07-06       -1.34        1.938566\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar =('C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_atualizado.csv')\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime e ordenar os dados\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "# data_dolar = data_dolar.sort_values(by='Data')\n",
    "\n",
    "# Remover a primeira linha\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Função para remover outliers\n",
    "def remove_outliers(df, column_names):\n",
    "    for column in column_names:\n",
    "        Q1 = df[column].quantile(0.20)\n",
    "        Q3 = df[column].quantile(0.80)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 0.4 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Aplicar a remoção de outliers\n",
    "numeric_columns = data_dolar.select_dtypes(include=[np.number]).columns.tolist()\n",
    "data_dolar = remove_outliers(data_dolar, numeric_columns)\n",
    "\n",
    "# Dividir os dados em treino, teste e validação\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2020-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic','OperacoesSeleic','UltimoEUR', 'Preco_Dolar', 'Preco_Real','Dif_Preco_Real'])\n",
    "\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data','Pontos', 'Dif_Preco_Dolar','TaxaSelic','OperacoesSeleic','UltimoEUR', 'Preco_Dolar', 'Preco_Real','Dif_Preco_Real'])\n",
    "\n",
    "# Calcular a média para as colunas e substituir NaN pela média\n",
    "mean_values_train = X_train.mean()\n",
    "X_train.fillna(mean_values_train, inplace=True)\n",
    "\n",
    "mean_values_test = X_test.mean()\n",
    "X_test.fillna(mean_values_test, inplace=True)\n",
    "\n",
    "# Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Treinar o modelo de regressão linear\n",
    "model = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "#model = lgb.LGBMRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular as métricas de desempenho\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "\n",
    "# Criar um DataFrame com as datas, valores reais e previstos\n",
    "resultados = pd.DataFrame()\n",
    "resultados['Data'] = test_data['Data']\n",
    "resultados['Valor_Real'] = y_test\n",
    "resultados['Valor_Previsto'] = y_pred\n",
    "\n",
    "# Exibir os primeiros registros para verificar\n",
    "print(resultados.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 11.64856444442459\n",
      "MAE: 2.5378110375356426\n",
      "R^2: 6.189585840199463e-05\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar = 'C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_atualizado.csv'\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime e definir como índice\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "data_dolar = data_dolar.set_index('Data')\n",
    "\n",
    "# Identificar e tratar datas duplicadas (mantendo a primeira ocorrência)\n",
    "data_dolar = data_dolar[~data_dolar.index.duplicated(keep='first')]\n",
    "\n",
    "# Redefinir a frequência para diária\n",
    "data_dolar = data_dolar.asfreq('D')\n",
    "\n",
    "# Tratar valores faltantes (por exemplo, preenchendo com o valor anterior)\n",
    "data_dolar = data_dolar.fillna(method='ffill')\n",
    "\n",
    "# Selecionar a coluna de interesse para a análise ARIMA\n",
    "y = data_dolar['Dif_Preco_Dolar']\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_end = pd.to_datetime(\"2020-01-01\")\n",
    "y_train = y[y.index < train_end]\n",
    "y_test = y[y.index >= train_end]\n",
    "\n",
    "# Definir e ajustar o modelo ARIMA\n",
    "p = 1  # Autoregressivo\n",
    "d = 1  # Diferenciação\n",
    "q = 1  # Média móvel\n",
    "model = ARIMA(y_train, order=(p, d, q))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model_fit.forecast(steps=len(y_test))\n",
    "\n",
    "# Calcular métricas de desempenho\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Exibir resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55/55 - 2s - loss: 3.4136 - 2s/epoch - 33ms/step\n",
      "Epoch 2/100\n",
      "55/55 - 0s - loss: 3.3149 - 101ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "55/55 - 0s - loss: 3.2934 - 100ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "55/55 - 0s - loss: 3.2817 - 96ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "55/55 - 0s - loss: 3.2835 - 96ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "55/55 - 0s - loss: 3.2842 - 95ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "55/55 - 0s - loss: 3.2744 - 97ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "55/55 - 0s - loss: 3.2678 - 98ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "55/55 - 0s - loss: 3.2653 - 114ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "55/55 - 0s - loss: 3.2640 - 101ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "55/55 - 0s - loss: 3.2640 - 113ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "55/55 - 0s - loss: 3.2613 - 120ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "55/55 - 0s - loss: 3.2659 - 102ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "55/55 - 0s - loss: 3.2572 - 101ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "55/55 - 0s - loss: 3.2644 - 98ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "55/55 - 0s - loss: 3.2523 - 98ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "55/55 - 0s - loss: 3.2574 - 97ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "55/55 - 0s - loss: 3.2560 - 111ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "55/55 - 0s - loss: 3.2477 - 98ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "55/55 - 0s - loss: 3.2529 - 94ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "55/55 - 0s - loss: 3.2469 - 97ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "55/55 - 0s - loss: 3.2426 - 100ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "55/55 - 0s - loss: 3.2385 - 101ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "55/55 - 0s - loss: 3.2398 - 119ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "55/55 - 0s - loss: 3.2420 - 111ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "55/55 - 0s - loss: 3.2307 - 111ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "55/55 - 0s - loss: 3.2387 - 105ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "55/55 - 0s - loss: 3.2430 - 96ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "55/55 - 0s - loss: 3.2465 - 96ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "55/55 - 0s - loss: 3.2289 - 92ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "55/55 - 0s - loss: 3.2258 - 100ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "55/55 - 0s - loss: 3.2235 - 99ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "55/55 - 0s - loss: 3.2233 - 97ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "55/55 - 0s - loss: 3.2281 - 93ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "55/55 - 0s - loss: 3.2094 - 97ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "55/55 - 0s - loss: 3.2157 - 96ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "55/55 - 0s - loss: 3.2117 - 94ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "55/55 - 0s - loss: 3.2071 - 95ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "55/55 - 0s - loss: 3.2172 - 95ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "55/55 - 0s - loss: 3.2022 - 96ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "55/55 - 0s - loss: 3.2023 - 98ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "55/55 - 0s - loss: 3.2103 - 99ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "55/55 - 0s - loss: 3.1892 - 101ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "55/55 - 0s - loss: 3.1910 - 95ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "55/55 - 0s - loss: 3.1884 - 99ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "55/55 - 0s - loss: 3.1874 - 96ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "55/55 - 0s - loss: 3.2016 - 94ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "55/55 - 0s - loss: 3.1674 - 94ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "55/55 - 0s - loss: 3.1860 - 98ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "55/55 - 0s - loss: 3.1672 - 95ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "55/55 - 0s - loss: 3.1753 - 96ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "55/55 - 0s - loss: 3.2027 - 98ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "55/55 - 0s - loss: 3.1656 - 96ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "55/55 - 0s - loss: 3.1753 - 112ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "55/55 - 0s - loss: 3.1648 - 95ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "55/55 - 0s - loss: 3.1665 - 100ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "55/55 - 0s - loss: 3.1587 - 94ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "55/55 - 0s - loss: 3.1582 - 93ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "55/55 - 0s - loss: 3.1642 - 95ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "55/55 - 0s - loss: 3.1959 - 94ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "55/55 - 0s - loss: 3.1458 - 94ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "55/55 - 0s - loss: 3.1626 - 96ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "55/55 - 0s - loss: 3.1371 - 100ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "55/55 - 0s - loss: 3.1313 - 98ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "55/55 - 0s - loss: 3.1104 - 92ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "55/55 - 0s - loss: 3.1137 - 97ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "55/55 - 0s - loss: 3.1303 - 96ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "55/55 - 0s - loss: 3.1212 - 91ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "55/55 - 0s - loss: 3.1216 - 94ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "55/55 - 0s - loss: 3.1174 - 95ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "55/55 - 0s - loss: 3.1148 - 93ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "55/55 - 0s - loss: 3.0810 - 93ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "55/55 - 0s - loss: 3.0902 - 100ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "55/55 - 0s - loss: 3.0521 - 98ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "55/55 - 0s - loss: 3.1273 - 100ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "55/55 - 0s - loss: 3.1011 - 96ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "55/55 - 0s - loss: 3.0757 - 98ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "55/55 - 0s - loss: 3.0566 - 94ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "55/55 - 0s - loss: 3.0442 - 99ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "55/55 - 0s - loss: 3.0309 - 99ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "55/55 - 0s - loss: 3.0086 - 95ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "55/55 - 0s - loss: 3.0935 - 93ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "55/55 - 0s - loss: 3.0203 - 95ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "55/55 - 0s - loss: 3.0339 - 98ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "55/55 - 0s - loss: 3.0304 - 98ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "55/55 - 0s - loss: 3.0274 - 96ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "55/55 - 0s - loss: 2.9984 - 107ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "55/55 - 0s - loss: 2.9563 - 93ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "55/55 - 0s - loss: 2.9985 - 96ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "55/55 - 0s - loss: 3.0635 - 99ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "55/55 - 0s - loss: 2.9699 - 93ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "55/55 - 0s - loss: 2.9625 - 97ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "55/55 - 0s - loss: 2.9298 - 95ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "55/55 - 0s - loss: 2.9310 - 100ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "55/55 - 0s - loss: 2.9420 - 98ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "55/55 - 0s - loss: 2.9179 - 98ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "55/55 - 0s - loss: 2.9276 - 97ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "55/55 - 0s - loss: 2.9195 - 94ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "55/55 - 0s - loss: 2.8981 - 97ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "55/55 - 0s - loss: 2.9824 - 94ms/epoch - 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "MSE: 0.8808579133323796\n",
      "MAE: 0.76358171461052\n",
      "R^2: 0.36161105132614746\n",
      "           Data  Valor_Real  Valor_Previsto\n",
      "6391 2023-06-26        0.45        0.651454\n",
      "6392 2023-06-27        0.10       -0.059972\n",
      "6395 2023-06-30        1.30        1.270375\n",
      "6396 2023-07-03       -0.63        0.148902\n",
      "6399 2023-07-06       -1.34       -0.493179\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar = 'C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_atualizado.csv'\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime e ordenar os dados\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Função para remover outliers\n",
    "def remove_outliers(df, column_names):\n",
    "    for column in column_names:\n",
    "        Q1 = df[column].quantile(0.20)\n",
    "        Q3 = df[column].quantile(0.80)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 0.4 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Aplicar a remoção de outliers\n",
    "numeric_columns = data_dolar.select_dtypes(include=[np.number]).columns.tolist()\n",
    "data_dolar = remove_outliers(data_dolar, numeric_columns)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2020-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "# Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Redimensionar os dados para o formato [samples, time_steps, features]\n",
    "X_train_scaled = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_scaled = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Construir o modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2])))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=2)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calcular as métricas de desempenho\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "\n",
    "# Criar um DataFrame com as datas, valores reais e previstos\n",
    "resultados = pd.DataFrame()\n",
    "resultados['Data'] = test_data['Data']\n",
    "resultados['Valor_Real'] = y_test\n",
    "resultados['Valor_Previsto'] = y_pred.flatten()  # Achatando a saída para combinar com o formato do y_test\n",
    "\n",
    "# Exibir os primeiros registros para verificar\n",
    "print(resultados.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.9275394800923671\n",
      "MAE: 0.839113278053472\n",
      "R^2: 0.3277792654327605\n",
      "         Data  Valor_Real  Valor_Previsto\n",
      "0  2023-06-26        0.45        1.403968\n",
      "1  2023-06-27        0.10       -1.003845\n",
      "2  2023-06-30        1.30        2.252853\n",
      "3  2023-07-03       -0.63       -0.094444\n",
      "4  2023-07-06       -1.34       -2.022010\n",
      "5  2023-07-13        1.85        0.812661\n",
      "6  2023-07-18       -0.39        0.288551\n",
      "7  2023-07-21        2.79        1.164435\n",
      "8  2023-07-24        2.62        1.912676\n",
      "9  2023-07-25       -0.15       -1.257611\n",
      "10 2023-07-26        0.39        1.037881\n",
      "11 2023-07-27       -0.67        0.535776\n",
      "12 2023-08-02        0.03       -0.073454\n",
      "13 2023-08-11       -1.40        0.302492\n",
      "14 2023-08-16        0.19        0.523376\n",
      "15 2023-08-18        0.25       -0.571402\n",
      "16 2023-08-21        0.32       -0.066038\n",
      "17 2023-08-22        1.15        1.526829\n",
      "18 2023-08-28        1.29       -0.063466\n",
      "19 2023-09-04        0.78        0.829645\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar = 'C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_atualizado.csv'\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime e ordenar os dados\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "\n",
    "# Remover a primeira linha\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Função para remover outliers\n",
    "def remove_outliers(df, column_names):\n",
    "    for column in column_names:\n",
    "        Q1 = df[column].quantile(0.20)\n",
    "        Q3 = df[column].quantile(0.80)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 0.4 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Aplicar a remoção de outliers\n",
    "numeric_columns = data_dolar.select_dtypes(include=[np.number]).columns.tolist()\n",
    "data_dolar = remove_outliers(data_dolar, numeric_columns)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2020-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "# Calcular a média para as colunas e substituir NaN pela média\n",
    "mean_values_train = X_train.mean()\n",
    "X_train.fillna(mean_values_train, inplace=True)\n",
    "\n",
    "mean_values_test = X_test.mean()\n",
    "X_test.fillna(mean_values_test, inplace=True)\n",
    "\n",
    "# Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Treinar o modelo de regressão linear\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Definindo o tamanho da janela deslizante, por exemplo, 5 dias\n",
    "tamanho_da_janela = 30\n",
    "\n",
    "# Inicializando o DataFrame de resultados\n",
    "resultados = pd.DataFrame()\n",
    "\n",
    "# Fazendo previsões em uma janela deslizante\n",
    "for i in range(0, len(test_data), tamanho_da_janela):\n",
    "    # Selecionar os dados da janela atual\n",
    "    X_test_janela = X_test.iloc[i:i+tamanho_da_janela]\n",
    "    y_test_janela = y_test.iloc[i:i+tamanho_da_janela]\n",
    "    datas_janela = test_data['Data'].iloc[i:i+tamanho_da_janela]\n",
    "\n",
    "    # Prever os valores para a janela atual\n",
    "    y_pred_janela = model.predict(X_test_janela)\n",
    "\n",
    "    # Armazenar os resultados\n",
    "    janela_resultados = pd.DataFrame({\n",
    "        'Data': datas_janela,\n",
    "        'Valor_Real': y_test_janela,\n",
    "        'Valor_Previsto': y_pred_janela\n",
    "    })\n",
    "    resultados = pd.concat([resultados, janela_resultados], ignore_index=True)\n",
    "\n",
    "# Calcular as métricas de desempenho para todo o período de teste\n",
    "mse = mean_squared_error(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "mae = mean_absolute_error(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "r2 = r2_score(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "print(resultados.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 4.774370601507938\n",
      "MAE: 1.8219976190476193\n",
      "R^2: -0.8375899191562914\n",
      "           Data  Valor_Real  Valor_Previsto\n",
      "5527 2020-01-07       -0.83         -0.0092\n",
      "5529 2020-01-09       -2.08          0.3886\n",
      "5530 2020-01-10        1.16         -0.0817\n",
      "5531 2020-01-13       -3.78          0.2513\n",
      "5532 2020-01-14       -0.44          0.3201\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar = 'C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_atualizado.csv'\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "\n",
    "# Remover a primeira linha\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Função para remover outliers\n",
    "def remove_outliers(df, column_names):\n",
    "    for column in column_names:\n",
    "        Q1 = df[column].quantile(0.20)\n",
    "        Q3 = df[column].quantile(0.80)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.2 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Aplicar a remoção de outliers\n",
    "numeric_columns = data_dolar.select_dtypes(include=[np.number]).columns.tolist()\n",
    "data_dolar = remove_outliers(data_dolar, numeric_columns)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2020-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "# Calcular a média para as colunas e substituir NaN pela média\n",
    "mean_values_train = X_train.mean()\n",
    "X_train.fillna(mean_values_train, inplace=True)\n",
    "\n",
    "mean_values_test = X_test.mean()\n",
    "X_test.fillna(mean_values_test, inplace=True)\n",
    "\n",
    "# Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Treinar o modelo de Random Forest\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular as métricas de desempenho\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "\n",
    "# Criar um DataFrame com as datas, valores reais e previstos\n",
    "resultados = pd.DataFrame()\n",
    "resultados['Data'] = test_data['Data']\n",
    "resultados['Valor_Real'] = y_test\n",
    "resultados['Valor_Previsto'] = y_pred\n",
    "\n",
    "# Exibir os primeiros registros para verificar\n",
    "print(resultados.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3.5576828395238103\n",
      "MAE: 1.5515880952380956\n",
      "R^2: -0.36930344690867933\n",
      "         Data  Valor_Real  Valor_Previsto\n",
      "0  2020-01-07       -0.83          0.5165\n",
      "1  2020-01-09       -2.08          0.1039\n",
      "2  2020-01-10        1.16          0.1843\n",
      "3  2020-01-13       -3.78          0.0860\n",
      "4  2020-01-14       -0.44          0.2536\n",
      "5  2020-01-15       -1.68         -0.0753\n",
      "6  2020-01-16       -0.97         -0.2445\n",
      "7  2020-01-17        1.16          0.0380\n",
      "8  2020-01-20       -0.93         -0.3680\n",
      "9  2020-01-21       -1.00         -0.2129\n",
      "10 2020-01-22        1.19          0.0662\n",
      "11 2020-01-23        0.52         -0.1438\n",
      "12 2020-01-24       -1.34         -0.2713\n",
      "13 2020-01-27       -2.92         -0.3079\n",
      "14 2020-01-28        0.53         -0.0642\n",
      "15 2020-01-29       -1.92         -0.4634\n",
      "16 2020-01-30       -1.22         -0.2677\n",
      "17 2020-01-31        0.28         -0.2239\n",
      "18 2020-02-06       -0.19         -0.0974\n",
      "19 2020-02-07       -0.42          0.0499\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar = 'C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_atualizado.csv'\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "\n",
    "# Remover a primeira linha\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Função para remover outliers\n",
    "def remove_outliers(df, column_names):\n",
    "    for column in column_names:\n",
    "        Q1 = df[column].quantile(0.20)\n",
    "        Q3 = df[column].quantile(0.80)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.2 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Aplicar a remoção de outliers\n",
    "numeric_columns = data_dolar.select_dtypes(include=[np.number]).columns.tolist()\n",
    "data_dolar = remove_outliers(data_dolar, numeric_columns)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2020-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "# Calcular a média para as colunas e substituir NaN pela média\n",
    "mean_values_train = X_train.mean()\n",
    "X_train.fillna(mean_values_train, inplace=True)\n",
    "mean_values_test = X_test.mean()\n",
    "X_test.fillna(mean_values_test, inplace=True)\n",
    "\n",
    "# Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Treinar o modelo de Random Forest\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Definindo o tamanho da janela deslizante, por exemplo, 5 dias\n",
    "tamanho_da_janela = 1\n",
    "\n",
    "# Inicializando o DataFrame de resultados\n",
    "resultados = pd.DataFrame()\n",
    "\n",
    "# Fazendo previsões em uma janela deslizante\n",
    "for i in range(0, len(test_data), tamanho_da_janela):\n",
    "    # Selecionar os dados da janela atual\n",
    "    X_test_janela = X_test.iloc[i:i+tamanho_da_janela]\n",
    "    y_test_janela = y_test.iloc[i:i+tamanho_da_janela]\n",
    "    datas_janela = test_data['Data'].iloc[i:i+tamanho_da_janela]\n",
    "\n",
    "    # Prever os valores para a janela atual\n",
    "    y_pred_janela = model.predict(X_test_janela)\n",
    "\n",
    "    # Armazenar os resultados\n",
    "    janela_resultados = pd.DataFrame({\n",
    "        'Data': datas_janela,\n",
    "        'Valor_Real': y_test_janela,\n",
    "        'Valor_Previsto': y_pred_janela\n",
    "    })\n",
    "    resultados = pd.concat([resultados, janela_resultados], ignore_index=True)\n",
    "\n",
    "# Calcular as métricas de desempenho para todo o período de teste\n",
    "mse = mean_squared_error(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "mae = mean_absolute_error(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "r2 = r2_score(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "print(resultados.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3.9570341473015884\n",
      "MAE: 1.6424206349206354\n",
      "R^2: -0.523008301144869\n",
      "         Data  Valor_Real  Valor_Previsto\n",
      "0  2020-01-07       -0.83          0.1661\n",
      "1  2020-01-09       -2.08          0.0009\n",
      "2  2020-01-10        1.16         -0.0827\n",
      "3  2020-01-13       -3.78         -0.2738\n",
      "4  2020-01-14       -0.44          0.0804\n",
      "5  2020-01-15       -1.68         -0.1533\n",
      "6  2020-01-16       -0.97         -0.2727\n",
      "7  2020-01-17        1.16         -0.0938\n",
      "8  2020-01-20       -0.93         -0.4045\n",
      "9  2020-01-21       -1.00         -0.3433\n",
      "10 2020-01-22        1.19         -0.0695\n",
      "11 2020-01-23        0.52         -0.2620\n",
      "12 2020-01-24       -1.34         -0.3953\n",
      "13 2020-01-27       -2.92         -0.3882\n",
      "14 2020-01-28        0.53          0.1923\n",
      "15 2020-01-29       -1.92         -0.4514\n",
      "16 2020-01-30       -1.22         -0.2726\n",
      "17 2020-01-31        0.28         -0.3527\n",
      "18 2020-02-06       -0.19         -0.2504\n",
      "19 2020-02-07       -0.42         -0.0880\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar = 'C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_atualizado.csv'\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "\n",
    "# Remover a primeira linha\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Função para remover outliers\n",
    "def remove_outliers(df, column_names):\n",
    "    for column in column_names:\n",
    "        Q1 = df[column].quantile(0.20)\n",
    "        Q3 = df[column].quantile(0.80)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.2 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Aplicar a remoção de outliers\n",
    "numeric_columns = data_dolar.select_dtypes(include=[np.number]).columns.tolist()\n",
    "data_dolar = remove_outliers(data_dolar, numeric_columns)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2020-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "# Calcular a média para as colunas e substituir NaN pela média\n",
    "mean_values_train = X_train.mean()\n",
    "X_train.fillna(mean_values_train, inplace=True)\n",
    "mean_values_test = X_test.mean()\n",
    "X_test.fillna(mean_values_test, inplace=True)\n",
    "\n",
    "# Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Treinar o modelo de Random Forest\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Definindo o tamanho da janela deslizante, por exemplo, 5 dias\n",
    "tamanho_da_janela = 30\n",
    "\n",
    "# Inicializando o DataFrame de resultados\n",
    "resultados = pd.DataFrame()\n",
    "\n",
    "# Fazendo previsões em uma janela deslizante\n",
    "for i in range(0, len(test_data), tamanho_da_janela):\n",
    "    # Selecionar os dados da janela atual\n",
    "    X_test_janela = X_test.iloc[i:i+tamanho_da_janela]\n",
    "    y_test_janela = y_test.iloc[i:i+tamanho_da_janela]\n",
    "    datas_janela = test_data['Data'].iloc[i:i+tamanho_da_janela]\n",
    "\n",
    "    # Prever os valores para a janela atual\n",
    "    y_pred_janela = model.predict(X_test_janela)\n",
    "\n",
    "    # Armazenar os resultados\n",
    "    janela_resultados = pd.DataFrame({\n",
    "        'Data': datas_janela,\n",
    "        'Valor_Real': y_test_janela,\n",
    "        'Valor_Previsto': y_pred_janela\n",
    "    })\n",
    "    resultados = pd.concat([resultados, janela_resultados], ignore_index=True)\n",
    "\n",
    "# Calcular as métricas de desempenho para todo o período de teste\n",
    "mse = mean_squared_error(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "mae = mean_absolute_error(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "r2 = r2_score(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "print(resultados.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
