{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 26)) while a minimum of 1 is required by LinearRegression.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\milen\\OneDrive\\Documentos\\GitHub\\TCC\\new.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/milen/OneDrive/Documentos/GitHub/TCC/new.ipynb#W3sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/milen/OneDrive/Documentos/GitHub/TCC/new.ipynb#W3sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# Fazer previsões no conjunto de teste\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/milen/OneDrive/Documentos/GitHub/TCC/new.ipynb#W3sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/milen/OneDrive/Documentos/GitHub/TCC/new.ipynb#W3sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# Calcular as métricas de desempenho\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/milen/OneDrive/Documentos/GitHub/TCC/new.ipynb#W3sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m mse \u001b[39m=\u001b[39m mean_squared_error(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\milen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:354\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    341\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[39m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[39m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decision_function(X)\n",
      "File \u001b[1;32mc:\\Users\\milen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:337\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    335\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 337\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcoo\u001b[39;49m\u001b[39m\"\u001b[39;49m], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    338\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n",
      "File \u001b[1;32mc:\\Users\\milen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\milen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[0;32m    930\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 931\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    932\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    933\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    934\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    935\u001b[0m         )\n\u001b[0;32m    937\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    938\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 26)) while a minimum of 1 is required by LinearRegression."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar =('C:/Users/milen/OneDrive/Documentos/TCC/Bases/base_completa.csv')\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "\n",
    "# Separar os últimos 10 dias de dados\n",
    "ultimos_10_dias = data_dolar.tail(7)\n",
    "data_dolar = data_dolar.iloc[:-7]\n",
    "\n",
    "# Continuar com o pré-processamento como antes...\n",
    "\n",
    "# Remover a primeira linha\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Função para remover outliers\n",
    "def remove_outliers(df, column_names):\n",
    "    for column in column_names:\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Aplicar a remoção de outliers\n",
    "numeric_columns = data_dolar.select_dtypes(include=[np.number]).columns.tolist()\n",
    "data_dolar = remove_outliers(data_dolar, numeric_columns)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2022-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2022-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data','Dif_Preco_Dolar','Preco_Real', 'Dif_Preco_Real','Preco_Dolar'])\n",
    "\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data','Dif_Preco_Dolar','Preco_Real', 'Dif_Preco_Real','Preco_Dolar'])\n",
    "\n",
    "# Calcular a média para as colunas e substituir NaN pela média\n",
    "mean_values_train = X_train.mean()\n",
    "X_train.fillna(mean_values_train, inplace=True)\n",
    "\n",
    "mean_values_test = X_test.mean()\n",
    "X_test.fillna(mean_values_test, inplace=True)\n",
    "\n",
    "# Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Treinar o modelo de regressão linear\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular as métricas de desempenho\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "\n",
    "# Criar um DataFrame com as datas, valores reais e previstos\n",
    "resultados = pd.DataFrame()\n",
    "resultados['Data'] = test_data['Data']\n",
    "resultados['Valor_Real'] = y_test\n",
    "resultados['Valor_Previsto'] = y_pred\n",
    "\n",
    "# Exibir os primeiros registros para verificar\n",
    "print(resultados.head())\n",
    "\n",
    "# Preparar dados dos últimos 10 dias para a previsão\n",
    "X_ultimos_10_dias = ultimos_10_dias.drop(columns=['Data','Dif_Preco_Dolar','Preco_Real', 'Dif_Preco_Real','Preco_Dolar'])\n",
    "X_ultimos_10_dias.fillna(mean_values_train, inplace=True)\n",
    "\n",
    "# Prever os valores para 'ultimos_10_dias'\n",
    "y_ultimos_10_dias_pred = model.predict(X_ultimos_10_dias)\n",
    "\n",
    "# Comparar as previsões com os valores reais\n",
    "ultimos_10_dias['Valor_Previsto'] = y_ultimos_10_dias_pred\n",
    "print(ultimos_10_dias[['Data', 'Dif_Preco_Dolar', 'Valor_Previsto']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O MELHOR MELHOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.4144627386124147\n",
      "MAE: 0.93425207546037\n",
      "R^2: 0.4184378432547554\n",
      "           Data  Valor_Real  Valor_Previsto\n",
      "4192 2020-01-03       -1.07       -0.282553\n",
      "4194 2020-01-07       -0.83        0.409178\n",
      "4196 2020-01-09       -2.08       -0.173142\n",
      "4197 2020-01-10        1.16        0.091813\n",
      "4199 2020-01-14       -0.44        0.481151\n",
      "4200 2020-01-15       -1.68       -0.403290\n",
      "4201 2020-01-16       -0.97        0.164825\n",
      "4202 2020-01-17        1.16        0.844743\n",
      "4203 2020-01-21       -1.00       -0.038981\n",
      "4204 2020-01-22        1.19        0.609236\n",
      "4205 2020-01-23        0.52        0.637602\n",
      "4206 2020-01-24       -1.34        0.202053\n",
      "4208 2020-01-28        0.53        0.372333\n",
      "4209 2020-01-29       -1.92       -0.230156\n",
      "4210 2020-01-30       -1.22        0.025656\n",
      "4211 2020-01-31        0.28       -0.604892\n",
      "4213 2020-02-04       -0.38        0.156067\n",
      "4214 2020-02-05        1.04        0.758674\n",
      "4215 2020-02-06       -0.19       -0.326385\n",
      "4216 2020-02-07       -0.42       -0.087336\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar =('C:/Users/milen/OneDrive/Documentos/TCC/Bases/euro.csv')\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime e ordenar os dados\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "# data_dolar = data_dolar.sort_values(by='Data')\n",
    "\n",
    "# Remover a primeira linha\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Função para remover outliers\n",
    "def remove_outliers(df, column_names):\n",
    "    for column in column_names:\n",
    "        Q1 = df[column].quantile(0.20)\n",
    "        Q3 = df[column].quantile(0.80)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 0.4 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Aplicar a remoção de outliers\n",
    "numeric_columns = data_dolar.select_dtypes(include=[np.number]).columns.tolist()\n",
    "data_dolar = remove_outliers(data_dolar, numeric_columns)\n",
    "\n",
    "# Dividir os dados em treino, teste e validação\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2020-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real','Dif_Preco_Dolar'])\n",
    "\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real','Dif_Preco_Dolar'])\n",
    "\n",
    "# Calcular a média para as colunas e substituir NaN pela média\n",
    "mean_values_train = X_train.mean()\n",
    "X_train.fillna(mean_values_train, inplace=True)\n",
    "\n",
    "mean_values_test = X_test.mean()\n",
    "X_test.fillna(mean_values_test, inplace=True)\n",
    "\n",
    "# Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Treinar o modelo de regressão linear\n",
    "model = LinearRegression()\n",
    "#model = lgb.LGBMRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular as métricas de desempenho\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "\n",
    "# Criar um DataFrame com as datas, valores reais e previstos\n",
    "resultados = pd.DataFrame()\n",
    "resultados['Data'] = test_data['Data']\n",
    "resultados['Valor_Real'] = y_test\n",
    "resultados['Valor_Previsto'] = y_pred\n",
    "\n",
    "# Exibir os primeiros registros para verificar\n",
    "print(resultados.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... [seu código anterior permanece inalterado até o treinamento do modelo] ...\n",
    "\n",
    "# Definindo o tamanho da janela deslizante\n",
    "tamanho_da_janela = 5\n",
    "\n",
    "# Inicializando o DataFrame de resultados\n",
    "resultados = pd.DataFrame(columns=['Data', 'Valor_Real', 'Valor_Previsto'])\n",
    "\n",
    "# Fazendo previsões em uma janela deslizante\n",
    "for i in range(0, len(test_data), tamanho_da_janela):\n",
    "    # Selecionar os dados da janela atual\n",
    "    X_test_janela = X_test.iloc[i:i+tamanho_da_janela]\n",
    "    y_test_janela = y_test.iloc[i:i+tamanho_da_janela]\n",
    "    datas_janela = test_data['Data'].iloc[i:i+tamanho_da_janela]\n",
    "\n",
    "    # Prever os valores para a janela atual\n",
    "    y_pred_janela = model.predict(X_test_janela)\n",
    "\n",
    "    # Armazenar os resultados\n",
    "    janela_resultados = pd.DataFrame({\n",
    "        'Data': datas_janela,\n",
    "        'Valor_Real': y_test_janela,\n",
    "        'Valor_Previsto': y_pred_janela\n",
    "    })\n",
    "    resultados = resultados.append(janela_resultados, ignore_index=True)\n",
    "\n",
    "# Calcular as métricas de desempenho para todo o período de teste\n",
    "mse = mean_squared_error(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "mae = mean_absolute_error(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "r2 = r2_score(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "print(resultados.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3.1077767802435763\n",
      "MAE: 1.4787053674773167\n",
      "R^2: -1.2523159767585392\n",
      "           Data  Valor_Real  Valor_Previsto\n",
      "6391 2023-06-26        0.45        1.877941\n",
      "6392 2023-06-27        0.10        1.564456\n",
      "6395 2023-06-30        1.30        1.702488\n",
      "6396 2023-07-03       -0.63        1.720908\n",
      "6399 2023-07-06       -1.34        1.938566\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar =('C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_atualizado.csv')\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime e ordenar os dados\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "# data_dolar = data_dolar.sort_values(by='Data')\n",
    "\n",
    "# Remover a primeira linha\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Função para remover outliers\n",
    "def remove_outliers(df, column_names):\n",
    "    for column in column_names:\n",
    "        Q1 = df[column].quantile(0.20)\n",
    "        Q3 = df[column].quantile(0.80)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 0.4 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Aplicar a remoção de outliers\n",
    "numeric_columns = data_dolar.select_dtypes(include=[np.number]).columns.tolist()\n",
    "data_dolar = remove_outliers(data_dolar, numeric_columns)\n",
    "\n",
    "# Dividir os dados em treino, teste e validação\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2020-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic','OperacoesSeleic','UltimoEUR', 'Preco_Dolar', 'Preco_Real','Dif_Preco_Real'])\n",
    "\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data','Pontos', 'Dif_Preco_Dolar','TaxaSelic','OperacoesSeleic','UltimoEUR', 'Preco_Dolar', 'Preco_Real','Dif_Preco_Real'])\n",
    "\n",
    "# Calcular a média para as colunas e substituir NaN pela média\n",
    "mean_values_train = X_train.mean()\n",
    "X_train.fillna(mean_values_train, inplace=True)\n",
    "\n",
    "mean_values_test = X_test.mean()\n",
    "X_test.fillna(mean_values_test, inplace=True)\n",
    "\n",
    "# Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Treinar o modelo de regressão linear\n",
    "model = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "#model = lgb.LGBMRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular as métricas de desempenho\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "\n",
    "# Criar um DataFrame com as datas, valores reais e previstos\n",
    "resultados = pd.DataFrame()\n",
    "resultados['Data'] = test_data['Data']\n",
    "resultados['Valor_Real'] = y_test\n",
    "resultados['Valor_Previsto'] = y_pred\n",
    "\n",
    "# Exibir os primeiros registros para verificar\n",
    "print(resultados.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 11.64856444442459\n",
      "MAE: 2.5378110375356426\n",
      "R^2: 6.189585840199463e-05\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar = 'C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_atualizado.csv'\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime e definir como índice\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "data_dolar = data_dolar.set_index('Data')\n",
    "\n",
    "# Identificar e tratar datas duplicadas (mantendo a primeira ocorrência)\n",
    "data_dolar = data_dolar[~data_dolar.index.duplicated(keep='first')]\n",
    "\n",
    "# Redefinir a frequência para diária\n",
    "data_dolar = data_dolar.asfreq('D')\n",
    "\n",
    "# Tratar valores faltantes (por exemplo, preenchendo com o valor anterior)\n",
    "data_dolar = data_dolar.fillna(method='ffill')\n",
    "\n",
    "# Selecionar a coluna de interesse para a análise ARIMA\n",
    "y = data_dolar['Dif_Preco_Dolar']\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_end = pd.to_datetime(\"2020-01-01\")\n",
    "y_train = y[y.index < train_end]\n",
    "y_test = y[y.index >= train_end]\n",
    "\n",
    "# Definir e ajustar o modelo ARIMA\n",
    "p = 1  # Autoregressivo\n",
    "d = 1  # Diferenciação\n",
    "q = 1  # Média móvel\n",
    "model = ARIMA(y_train, order=(p, d, q))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model_fit.forecast(steps=len(y_test))\n",
    "\n",
    "# Calcular métricas de desempenho\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Exibir resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43/43 - 2s - loss: 3.2658 - 2s/epoch - 53ms/step\n",
      "Epoch 2/100\n",
      "43/43 - 0s - loss: 3.1321 - 69ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "43/43 - 0s - loss: 3.0891 - 59ms/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "43/43 - 0s - loss: 3.0767 - 69ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "43/43 - 0s - loss: 3.0652 - 71ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "43/43 - 0s - loss: 3.0642 - 67ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "43/43 - 0s - loss: 3.0611 - 60ms/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "43/43 - 0s - loss: 3.0644 - 75ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "43/43 - 0s - loss: 3.0531 - 68ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "43/43 - 0s - loss: 3.0467 - 72ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "43/43 - 0s - loss: 3.0477 - 72ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "43/43 - 0s - loss: 3.0499 - 65ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "43/43 - 0s - loss: 3.0457 - 63ms/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "43/43 - 0s - loss: 3.0424 - 62ms/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "43/43 - 0s - loss: 3.0357 - 61ms/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "43/43 - 0s - loss: 3.0344 - 63ms/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "43/43 - 0s - loss: 3.0341 - 62ms/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "43/43 - 0s - loss: 3.0550 - 63ms/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "43/43 - 0s - loss: 3.0365 - 62ms/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "43/43 - 0s - loss: 3.0319 - 59ms/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "43/43 - 0s - loss: 3.0334 - 66ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "43/43 - 0s - loss: 3.0266 - 84ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "43/43 - 0s - loss: 3.0282 - 67ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "43/43 - 0s - loss: 3.0315 - 60ms/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "43/43 - 0s - loss: 3.0310 - 62ms/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "43/43 - 0s - loss: 3.0245 - 61ms/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "43/43 - 0s - loss: 3.0249 - 65ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "43/43 - 0s - loss: 3.0296 - 65ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "43/43 - 0s - loss: 3.0371 - 65ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "43/43 - 0s - loss: 3.0231 - 62ms/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "43/43 - 0s - loss: 3.0208 - 62ms/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "43/43 - 0s - loss: 3.0211 - 69ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "43/43 - 0s - loss: 3.0239 - 63ms/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "43/43 - 0s - loss: 3.0295 - 61ms/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "43/43 - 0s - loss: 3.0260 - 60ms/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "43/43 - 0s - loss: 3.0182 - 62ms/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "43/43 - 0s - loss: 3.0212 - 64ms/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "43/43 - 0s - loss: 3.0214 - 68ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "43/43 - 0s - loss: 3.0177 - 71ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "43/43 - 0s - loss: 3.0394 - 67ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "43/43 - 0s - loss: 3.0219 - 66ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "43/43 - 0s - loss: 3.0151 - 65ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "43/43 - 0s - loss: 3.0145 - 77ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "43/43 - 0s - loss: 3.0055 - 70ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "43/43 - 0s - loss: 3.0098 - 61ms/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "43/43 - 0s - loss: 3.0182 - 61ms/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "43/43 - 0s - loss: 3.0124 - 62ms/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "43/43 - 0s - loss: 2.9997 - 68ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "43/43 - 0s - loss: 3.0070 - 66ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "43/43 - 0s - loss: 3.0156 - 64ms/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "43/43 - 0s - loss: 3.0122 - 66ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "43/43 - 0s - loss: 3.0068 - 68ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "43/43 - 0s - loss: 3.0058 - 69ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "43/43 - 0s - loss: 2.9971 - 82ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "43/43 - 0s - loss: 3.0001 - 67ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "43/43 - 0s - loss: 3.0097 - 66ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "43/43 - 0s - loss: 3.0089 - 70ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "43/43 - 0s - loss: 2.9961 - 86ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "43/43 - 0s - loss: 2.9935 - 90ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "43/43 - 0s - loss: 2.9970 - 67ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "43/43 - 0s - loss: 2.9869 - 70ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "43/43 - 0s - loss: 2.9933 - 78ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "43/43 - 0s - loss: 2.9924 - 66ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "43/43 - 0s - loss: 2.9855 - 65ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "43/43 - 0s - loss: 2.9883 - 66ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "43/43 - 0s - loss: 2.9911 - 67ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "43/43 - 0s - loss: 2.9788 - 66ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "43/43 - 0s - loss: 2.9779 - 70ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "43/43 - 0s - loss: 2.9790 - 67ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "43/43 - 0s - loss: 2.9954 - 66ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "43/43 - 0s - loss: 2.9812 - 72ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "43/43 - 0s - loss: 2.9789 - 68ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "43/43 - 0s - loss: 2.9772 - 71ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "43/43 - 0s - loss: 2.9830 - 66ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "43/43 - 0s - loss: 2.9746 - 67ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "43/43 - 0s - loss: 2.9758 - 67ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "43/43 - 0s - loss: 2.9709 - 64ms/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "43/43 - 0s - loss: 2.9751 - 67ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "43/43 - 0s - loss: 2.9893 - 66ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "43/43 - 0s - loss: 2.9635 - 80ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "43/43 - 0s - loss: 2.9567 - 78ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "43/43 - 0s - loss: 2.9586 - 76ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "43/43 - 0s - loss: 2.9576 - 75ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "43/43 - 0s - loss: 2.9681 - 79ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "43/43 - 0s - loss: 2.9485 - 75ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "43/43 - 0s - loss: 2.9291 - 68ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "43/43 - 0s - loss: 2.9520 - 74ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "43/43 - 0s - loss: 2.9508 - 71ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "43/43 - 0s - loss: 2.9383 - 67ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "43/43 - 0s - loss: 2.9447 - 67ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "43/43 - 0s - loss: 2.9350 - 66ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "43/43 - 0s - loss: 2.9538 - 80ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "43/43 - 0s - loss: 2.9332 - 70ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "43/43 - 0s - loss: 2.9515 - 68ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "43/43 - 0s - loss: 2.9151 - 69ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "43/43 - 0s - loss: 2.9240 - 69ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "43/43 - 0s - loss: 2.9175 - 70ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "43/43 - 0s - loss: 2.9276 - 64ms/epoch - 1ms/step\n",
      "Epoch 99/100\n",
      "43/43 - 0s - loss: 2.9217 - 70ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "43/43 - 0s - loss: 2.9382 - 68ms/epoch - 2ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "MSE: 1.8397663412134704\n",
      "MAE: 1.154517684400082\n",
      "R^2: 0.14181837207762749\n",
      "           Data  Valor_Real  Valor_Previsto\n",
      "5040 2023-06-30        1.30        0.489289\n",
      "5041 2023-07-03       -0.63        0.319246\n",
      "5043 2023-07-06       -1.34        0.245868\n",
      "5048 2023-07-13        1.85        0.546206\n",
      "5051 2023-07-18       -0.39        0.438595\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar = 'C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_cme.csv'\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime e ordenar os dados\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Função para remover outliers\n",
    "def remove_outliers(df, column_names):\n",
    "    for column in column_names:\n",
    "        Q1 = df[column].quantile(0.20)\n",
    "        Q3 = df[column].quantile(0.80)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 0.4 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Aplicar a remoção de outliers\n",
    "numeric_columns = data_dolar.select_dtypes(include=[np.number]).columns.tolist()\n",
    "data_dolar = remove_outliers(data_dolar, numeric_columns)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2020-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "# Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Redimensionar os dados para o formato [samples, time_steps, features]\n",
    "X_train_scaled = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_scaled = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Construir o modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2])))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=2)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calcular as métricas de desempenho\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "\n",
    "# Criar um DataFrame com as datas, valores reais e previstos\n",
    "resultados = pd.DataFrame()\n",
    "resultados['Data'] = test_data['Data']\n",
    "resultados['Valor_Real'] = y_test\n",
    "resultados['Valor_Previsto'] = y_pred.flatten()  # Achatando a saída para combinar com o formato do y_test\n",
    "\n",
    "# Exibir os primeiros registros para verificar\n",
    "print(resultados.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.9275394800923671\n",
      "MAE: 0.839113278053472\n",
      "R^2: 0.3277792654327605\n",
      "         Data  Valor_Real  Valor_Previsto\n",
      "0  2023-06-26        0.45        1.403968\n",
      "1  2023-06-27        0.10       -1.003845\n",
      "2  2023-06-30        1.30        2.252853\n",
      "3  2023-07-03       -0.63       -0.094444\n",
      "4  2023-07-06       -1.34       -2.022010\n",
      "5  2023-07-13        1.85        0.812661\n",
      "6  2023-07-18       -0.39        0.288551\n",
      "7  2023-07-21        2.79        1.164435\n",
      "8  2023-07-24        2.62        1.912676\n",
      "9  2023-07-25       -0.15       -1.257611\n",
      "10 2023-07-26        0.39        1.037881\n",
      "11 2023-07-27       -0.67        0.535776\n",
      "12 2023-08-02        0.03       -0.073454\n",
      "13 2023-08-11       -1.40        0.302492\n",
      "14 2023-08-16        0.19        0.523376\n",
      "15 2023-08-18        0.25       -0.571402\n",
      "16 2023-08-21        0.32       -0.066038\n",
      "17 2023-08-22        1.15        1.526829\n",
      "18 2023-08-28        1.29       -0.063466\n",
      "19 2023-09-04        0.78        0.829645\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar = 'C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_atualizado.csv'\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime e ordenar os dados\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "\n",
    "# Remover a primeira linha\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Função para remover outliers\n",
    "def remove_outliers(df, column_names):\n",
    "    for column in column_names:\n",
    "        Q1 = df[column].quantile(0.20)\n",
    "        Q3 = df[column].quantile(0.80)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 0.4 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Aplicar a remoção de outliers\n",
    "numeric_columns = data_dolar.select_dtypes(include=[np.number]).columns.tolist()\n",
    "data_dolar = remove_outliers(data_dolar, numeric_columns)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2020-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "# Calcular a média para as colunas e substituir NaN pela média\n",
    "mean_values_train = X_train.mean()\n",
    "X_train.fillna(mean_values_train, inplace=True)\n",
    "\n",
    "mean_values_test = X_test.mean()\n",
    "X_test.fillna(mean_values_test, inplace=True)\n",
    "\n",
    "# Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Treinar o modelo de regressão linear\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Definindo o tamanho da janela deslizante, por exemplo, 5 dias\n",
    "tamanho_da_janela = 30\n",
    "\n",
    "# Inicializando o DataFrame de resultados\n",
    "resultados = pd.DataFrame()\n",
    "\n",
    "# Fazendo previsões em uma janela deslizante\n",
    "for i in range(0, len(test_data), tamanho_da_janela):\n",
    "    # Selecionar os dados da janela atual\n",
    "    X_test_janela = X_test.iloc[i:i+tamanho_da_janela]\n",
    "    y_test_janela = y_test.iloc[i:i+tamanho_da_janela]\n",
    "    datas_janela = test_data['Data'].iloc[i:i+tamanho_da_janela]\n",
    "\n",
    "    # Prever os valores para a janela atual\n",
    "    y_pred_janela = model.predict(X_test_janela)\n",
    "\n",
    "    # Armazenar os resultados\n",
    "    janela_resultados = pd.DataFrame({\n",
    "        'Data': datas_janela,\n",
    "        'Valor_Real': y_test_janela,\n",
    "        'Valor_Previsto': y_pred_janela\n",
    "    })\n",
    "    resultados = pd.concat([resultados, janela_resultados], ignore_index=True)\n",
    "\n",
    "# Calcular as métricas de desempenho para todo o período de teste\n",
    "mse = mean_squared_error(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "mae = mean_absolute_error(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "r2 = r2_score(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "print(resultados.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 4.774370601507938\n",
      "MAE: 1.8219976190476193\n",
      "R^2: -0.8375899191562914\n",
      "           Data  Valor_Real  Valor_Previsto\n",
      "5527 2020-01-07       -0.83         -0.0092\n",
      "5529 2020-01-09       -2.08          0.3886\n",
      "5530 2020-01-10        1.16         -0.0817\n",
      "5531 2020-01-13       -3.78          0.2513\n",
      "5532 2020-01-14       -0.44          0.3201\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar = 'C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_atualizado.csv'\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "\n",
    "# Remover a primeira linha\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Função para remover outliers\n",
    "def remove_outliers(df, column_names):\n",
    "    for column in column_names:\n",
    "        Q1 = df[column].quantile(0.20)\n",
    "        Q3 = df[column].quantile(0.80)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.2 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Aplicar a remoção de outliers\n",
    "numeric_columns = data_dolar.select_dtypes(include=[np.number]).columns.tolist()\n",
    "data_dolar = remove_outliers(data_dolar, numeric_columns)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2020-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "# Calcular a média para as colunas e substituir NaN pela média\n",
    "mean_values_train = X_train.mean()\n",
    "X_train.fillna(mean_values_train, inplace=True)\n",
    "\n",
    "mean_values_test = X_test.mean()\n",
    "X_test.fillna(mean_values_test, inplace=True)\n",
    "\n",
    "# Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Treinar o modelo de Random Forest\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular as métricas de desempenho\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "\n",
    "# Criar um DataFrame com as datas, valores reais e previstos\n",
    "resultados = pd.DataFrame()\n",
    "resultados['Data'] = test_data['Data']\n",
    "resultados['Valor_Real'] = y_test\n",
    "resultados['Valor_Previsto'] = y_pred\n",
    "\n",
    "# Exibir os primeiros registros para verificar\n",
    "print(resultados.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3.5576828395238103\n",
      "MAE: 1.5515880952380956\n",
      "R^2: -0.36930344690867933\n",
      "         Data  Valor_Real  Valor_Previsto\n",
      "0  2020-01-07       -0.83          0.5165\n",
      "1  2020-01-09       -2.08          0.1039\n",
      "2  2020-01-10        1.16          0.1843\n",
      "3  2020-01-13       -3.78          0.0860\n",
      "4  2020-01-14       -0.44          0.2536\n",
      "5  2020-01-15       -1.68         -0.0753\n",
      "6  2020-01-16       -0.97         -0.2445\n",
      "7  2020-01-17        1.16          0.0380\n",
      "8  2020-01-20       -0.93         -0.3680\n",
      "9  2020-01-21       -1.00         -0.2129\n",
      "10 2020-01-22        1.19          0.0662\n",
      "11 2020-01-23        0.52         -0.1438\n",
      "12 2020-01-24       -1.34         -0.2713\n",
      "13 2020-01-27       -2.92         -0.3079\n",
      "14 2020-01-28        0.53         -0.0642\n",
      "15 2020-01-29       -1.92         -0.4634\n",
      "16 2020-01-30       -1.22         -0.2677\n",
      "17 2020-01-31        0.28         -0.2239\n",
      "18 2020-02-06       -0.19         -0.0974\n",
      "19 2020-02-07       -0.42          0.0499\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar = 'C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_atualizado.csv'\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "\n",
    "# Remover a primeira linha\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Função para remover outliers\n",
    "def remove_outliers(df, column_names):\n",
    "    for column in column_names:\n",
    "        Q1 = df[column].quantile(0.20)\n",
    "        Q3 = df[column].quantile(0.80)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.2 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Aplicar a remoção de outliers\n",
    "numeric_columns = data_dolar.select_dtypes(include=[np.number]).columns.tolist()\n",
    "data_dolar = remove_outliers(data_dolar, numeric_columns)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2020-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "# Calcular a média para as colunas e substituir NaN pela média\n",
    "mean_values_train = X_train.mean()\n",
    "X_train.fillna(mean_values_train, inplace=True)\n",
    "mean_values_test = X_test.mean()\n",
    "X_test.fillna(mean_values_test, inplace=True)\n",
    "\n",
    "# Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Treinar o modelo de Random Forest\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Definindo o tamanho da janela deslizante, por exemplo, 5 dias\n",
    "tamanho_da_janela = 1\n",
    "\n",
    "# Inicializando o DataFrame de resultados\n",
    "resultados = pd.DataFrame()\n",
    "\n",
    "# Fazendo previsões em uma janela deslizante\n",
    "for i in range(0, len(test_data), tamanho_da_janela):\n",
    "    # Selecionar os dados da janela atual\n",
    "    X_test_janela = X_test.iloc[i:i+tamanho_da_janela]\n",
    "    y_test_janela = y_test.iloc[i:i+tamanho_da_janela]\n",
    "    datas_janela = test_data['Data'].iloc[i:i+tamanho_da_janela]\n",
    "\n",
    "    # Prever os valores para a janela atual\n",
    "    y_pred_janela = model.predict(X_test_janela)\n",
    "\n",
    "    # Armazenar os resultados\n",
    "    janela_resultados = pd.DataFrame({\n",
    "        'Data': datas_janela,\n",
    "        'Valor_Real': y_test_janela,\n",
    "        'Valor_Previsto': y_pred_janela\n",
    "    })\n",
    "    resultados = pd.concat([resultados, janela_resultados], ignore_index=True)\n",
    "\n",
    "# Calcular as métricas de desempenho para todo o período de teste\n",
    "mse = mean_squared_error(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "mae = mean_absolute_error(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "r2 = r2_score(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "print(resultados.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "115/115 - 4s - loss: 0.0050 - 4s/epoch - 33ms/step\n",
      "Epoch 2/100\n",
      "115/115 - 1s - loss: 6.7618e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "115/115 - 1s - loss: 6.6512e-04 - 1s/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "115/115 - 1s - loss: 6.7020e-04 - 1s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "115/115 - 1s - loss: 6.5666e-04 - 1s/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "115/115 - 1s - loss: 5.9453e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "115/115 - 1s - loss: 5.8878e-04 - 1s/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "115/115 - 1s - loss: 5.4854e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 9/100\n",
      "115/115 - 1s - loss: 5.5160e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 10/100\n",
      "115/115 - 1s - loss: 4.7383e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "115/115 - 1s - loss: 4.8700e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "115/115 - 1s - loss: 4.9810e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "115/115 - 1s - loss: 4.1781e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "115/115 - 1s - loss: 3.9129e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "115/115 - 1s - loss: 4.1969e-04 - 1s/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "115/115 - 1s - loss: 3.8287e-04 - 1s/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "115/115 - 1s - loss: 3.5120e-04 - 1s/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "115/115 - 1s - loss: 3.5411e-04 - 1s/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "115/115 - 1s - loss: 3.3063e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 20/100\n",
      "115/115 - 1s - loss: 3.5819e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 21/100\n",
      "115/115 - 1s - loss: 3.4991e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 22/100\n",
      "115/115 - 1s - loss: 3.2467e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "115/115 - 1s - loss: 2.9721e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "115/115 - 1s - loss: 2.8506e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "115/115 - 1s - loss: 3.1842e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 26/100\n",
      "115/115 - 1s - loss: 2.7873e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 27/100\n",
      "115/115 - 1s - loss: 2.6636e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "115/115 - 1s - loss: 2.6599e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "115/115 - 1s - loss: 2.7144e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "115/115 - 1s - loss: 2.9049e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "115/115 - 1s - loss: 2.7464e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "115/115 - 1s - loss: 2.9170e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "115/115 - 1s - loss: 2.8054e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "115/115 - 1s - loss: 2.7670e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "115/115 - 1s - loss: 2.6795e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "115/115 - 1s - loss: 2.6784e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "115/115 - 1s - loss: 2.6801e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "115/115 - 1s - loss: 2.7283e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "115/115 - 1s - loss: 2.8569e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "115/115 - 1s - loss: 2.7015e-04 - 1s/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "115/115 - 1s - loss: 2.7472e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "115/115 - 1s - loss: 2.7497e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "115/115 - 1s - loss: 2.7825e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "115/115 - 1s - loss: 2.7721e-04 - 1s/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "115/115 - 1s - loss: 2.6629e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 46/100\n",
      "115/115 - 1s - loss: 2.6672e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "115/115 - 1s - loss: 2.7920e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "115/115 - 1s - loss: 2.5686e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "115/115 - 1s - loss: 2.6732e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "115/115 - 1s - loss: 2.8187e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "115/115 - 1s - loss: 2.9749e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 52/100\n",
      "115/115 - 1s - loss: 2.7273e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "115/115 - 1s - loss: 2.6587e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 54/100\n",
      "115/115 - 1s - loss: 2.6972e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "115/115 - 1s - loss: 2.7139e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 56/100\n",
      "115/115 - 1s - loss: 2.7480e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 57/100\n",
      "115/115 - 1s - loss: 2.8155e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 58/100\n",
      "115/115 - 1s - loss: 2.5199e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 59/100\n",
      "115/115 - 1s - loss: 2.5974e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "115/115 - 1s - loss: 2.5445e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "115/115 - 1s - loss: 2.5548e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 62/100\n",
      "115/115 - 1s - loss: 2.4677e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 63/100\n",
      "115/115 - 1s - loss: 2.4461e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 64/100\n",
      "115/115 - 1s - loss: 2.5050e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 65/100\n",
      "115/115 - 1s - loss: 2.5359e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 66/100\n",
      "115/115 - 1s - loss: 2.7136e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 67/100\n",
      "115/115 - 1s - loss: 2.6710e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 68/100\n",
      "115/115 - 1s - loss: 2.7199e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 69/100\n",
      "115/115 - 1s - loss: 2.6585e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 70/100\n",
      "115/115 - 1s - loss: 2.9474e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 71/100\n",
      "115/115 - 1s - loss: 2.5632e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 72/100\n",
      "115/115 - 1s - loss: 2.4754e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 73/100\n",
      "115/115 - 1s - loss: 2.4835e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 74/100\n",
      "115/115 - 1s - loss: 2.6410e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 75/100\n",
      "115/115 - 1s - loss: 2.5224e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 76/100\n",
      "115/115 - 1s - loss: 2.6173e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 77/100\n",
      "115/115 - 1s - loss: 2.6304e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 78/100\n",
      "115/115 - 1s - loss: 2.6860e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 79/100\n",
      "115/115 - 1s - loss: 2.4642e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 80/100\n",
      "115/115 - 1s - loss: 2.5767e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 81/100\n",
      "115/115 - 1s - loss: 2.6268e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 82/100\n",
      "115/115 - 1s - loss: 2.7204e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 83/100\n",
      "115/115 - 1s - loss: 2.7733e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 84/100\n",
      "115/115 - 1s - loss: 2.4677e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 85/100\n",
      "115/115 - 1s - loss: 2.5703e-04 - 1s/epoch - 9ms/step\n",
      "Epoch 86/100\n",
      "115/115 - 1s - loss: 2.4567e-04 - 1s/epoch - 9ms/step\n",
      "Epoch 87/100\n",
      "115/115 - 1s - loss: 2.4808e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 88/100\n",
      "115/115 - 1s - loss: 2.4770e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 89/100\n",
      "115/115 - 1s - loss: 2.5221e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 90/100\n",
      "115/115 - 1s - loss: 2.5033e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 91/100\n",
      "115/115 - 1s - loss: 2.5798e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 92/100\n",
      "115/115 - 1s - loss: 2.4851e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 93/100\n",
      "115/115 - 1s - loss: 2.5155e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 94/100\n",
      "115/115 - 1s - loss: 2.4397e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 95/100\n",
      "115/115 - 1s - loss: 2.4703e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 96/100\n",
      "115/115 - 1s - loss: 2.5125e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 97/100\n",
      "115/115 - 1s - loss: 2.4747e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 98/100\n",
      "115/115 - 1s - loss: 2.5002e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 99/100\n",
      "115/115 - 1s - loss: 2.4356e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 100/100\n",
      "115/115 - 1s - loss: 2.7424e-04 - 1s/epoch - 11ms/step\n",
      "9/9 [==============================] - 1s 4ms/step\n",
      "MSE: 0.006530528328730492\n",
      "MAE: 0.06618792930892939\n",
      "R^2: 0.8323636480053409\n",
      "           Data  Valor_Real  Valor_Previsto\n",
      "4203 2020-01-21    0.908555        0.902224\n",
      "4204 2020-01-22    0.897921        0.915778\n",
      "4205 2020-01-23    0.887032        0.908008\n",
      "4206 2020-01-24    0.887104        0.898672\n",
      "4208 2020-01-28    0.891802        0.896697\n",
      "Epoch 1/100\n",
      "115/115 - 4s - loss: 0.0068 - 4s/epoch - 36ms/step\n",
      "Epoch 2/100\n",
      "115/115 - 1s - loss: 4.9197e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 3/100\n",
      "115/115 - 1s - loss: 5.1305e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "115/115 - 1s - loss: 4.8221e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "115/115 - 1s - loss: 5.1857e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "115/115 - 1s - loss: 4.7234e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "115/115 - 1s - loss: 4.4419e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 8/100\n",
      "115/115 - 1s - loss: 5.2587e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 9/100\n",
      "115/115 - 1s - loss: 4.9660e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "115/115 - 1s - loss: 3.9169e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "115/115 - 1s - loss: 4.0296e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 12/100\n",
      "115/115 - 1s - loss: 3.6371e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "115/115 - 1s - loss: 3.7381e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "115/115 - 1s - loss: 3.5747e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "115/115 - 1s - loss: 3.3271e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 16/100\n",
      "115/115 - 1s - loss: 2.9263e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "115/115 - 1s - loss: 2.9293e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "115/115 - 1s - loss: 2.9051e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "115/115 - 1s - loss: 3.0549e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "115/115 - 1s - loss: 3.3200e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "115/115 - 1s - loss: 2.6221e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "115/115 - 1s - loss: 2.4329e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "115/115 - 1s - loss: 2.5098e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "115/115 - 1s - loss: 2.3463e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 25/100\n",
      "115/115 - 1s - loss: 2.5862e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "115/115 - 1s - loss: 2.1812e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "115/115 - 1s - loss: 2.2386e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "115/115 - 1s - loss: 2.1161e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "115/115 - 1s - loss: 2.1036e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 30/100\n",
      "115/115 - 1s - loss: 2.1251e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "115/115 - 1s - loss: 2.0871e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "115/115 - 1s - loss: 2.3509e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 33/100\n",
      "115/115 - 1s - loss: 2.3372e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 34/100\n",
      "115/115 - 1s - loss: 2.0010e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 35/100\n",
      "115/115 - 1s - loss: 1.9969e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "115/115 - 1s - loss: 2.0468e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 37/100\n",
      "115/115 - 1s - loss: 2.2457e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "115/115 - 1s - loss: 2.0691e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 39/100\n",
      "115/115 - 1s - loss: 2.1571e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 40/100\n",
      "115/115 - 1s - loss: 1.9738e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "115/115 - 1s - loss: 2.3864e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 42/100\n",
      "115/115 - 1s - loss: 2.0600e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "115/115 - 1s - loss: 2.0242e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 44/100\n",
      "115/115 - 1s - loss: 2.0139e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "115/115 - 1s - loss: 2.0074e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 46/100\n",
      "115/115 - 1s - loss: 2.3182e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "115/115 - 1s - loss: 2.2428e-04 - 1s/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "115/115 - 1s - loss: 1.9193e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "115/115 - 1s - loss: 2.6862e-04 - 1s/epoch - 12ms/step\n",
      "Epoch 50/100\n",
      "115/115 - 1s - loss: 1.9323e-04 - 1s/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "115/115 - 1s - loss: 1.8372e-04 - 1s/epoch - 12ms/step\n",
      "Epoch 52/100\n",
      "115/115 - 2s - loss: 1.9969e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 53/100\n",
      "115/115 - 2s - loss: 2.3977e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 54/100\n",
      "115/115 - 2s - loss: 2.0996e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 55/100\n",
      "115/115 - 2s - loss: 2.0443e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 56/100\n",
      "115/115 - 1s - loss: 2.0645e-04 - 1s/epoch - 13ms/step\n",
      "Epoch 57/100\n",
      "115/115 - 2s - loss: 1.8910e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 58/100\n",
      "115/115 - 2s - loss: 2.0213e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 59/100\n",
      "115/115 - 2s - loss: 2.3738e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 60/100\n",
      "115/115 - 2s - loss: 2.1688e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 61/100\n",
      "115/115 - 2s - loss: 1.8581e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 62/100\n",
      "115/115 - 2s - loss: 1.9359e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 63/100\n",
      "115/115 - 1s - loss: 2.1360e-04 - 1s/epoch - 13ms/step\n",
      "Epoch 64/100\n",
      "115/115 - 1s - loss: 1.8177e-04 - 1s/epoch - 13ms/step\n",
      "Epoch 65/100\n",
      "115/115 - 2s - loss: 1.8764e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 66/100\n",
      "115/115 - 2s - loss: 1.9071e-04 - 2s/epoch - 15ms/step\n",
      "Epoch 67/100\n",
      "115/115 - 2s - loss: 2.4214e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 68/100\n",
      "115/115 - 2s - loss: 2.1294e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 69/100\n",
      "115/115 - 2s - loss: 1.9740e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 70/100\n",
      "115/115 - 2s - loss: 1.8519e-04 - 2s/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "115/115 - 2s - loss: 2.0223e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 72/100\n",
      "115/115 - 2s - loss: 2.1857e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 73/100\n",
      "115/115 - 2s - loss: 1.8018e-04 - 2s/epoch - 15ms/step\n",
      "Epoch 74/100\n",
      "115/115 - 2s - loss: 1.8148e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 75/100\n",
      "115/115 - 2s - loss: 1.8800e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 76/100\n",
      "115/115 - 2s - loss: 1.8478e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 77/100\n",
      "115/115 - 2s - loss: 1.8078e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 78/100\n",
      "115/115 - 1s - loss: 1.9089e-04 - 1s/epoch - 13ms/step\n",
      "Epoch 79/100\n",
      "115/115 - 1s - loss: 1.9557e-04 - 1s/epoch - 12ms/step\n",
      "Epoch 80/100\n",
      "115/115 - 2s - loss: 2.0428e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 81/100\n",
      "115/115 - 1s - loss: 1.8730e-04 - 1s/epoch - 13ms/step\n",
      "Epoch 82/100\n",
      "115/115 - 1s - loss: 1.8835e-04 - 1s/epoch - 12ms/step\n",
      "Epoch 83/100\n",
      "115/115 - 1s - loss: 1.8748e-04 - 1s/epoch - 13ms/step\n",
      "Epoch 84/100\n",
      "115/115 - 2s - loss: 1.7768e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 85/100\n",
      "115/115 - 2s - loss: 2.1688e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 86/100\n",
      "115/115 - 1s - loss: 2.2410e-04 - 1s/epoch - 13ms/step\n",
      "Epoch 87/100\n",
      "115/115 - 1s - loss: 1.8361e-04 - 1s/epoch - 13ms/step\n",
      "Epoch 88/100\n",
      "115/115 - 1s - loss: 1.9095e-04 - 1s/epoch - 13ms/step\n",
      "Epoch 89/100\n",
      "115/115 - 1s - loss: 1.9945e-04 - 1s/epoch - 13ms/step\n",
      "Epoch 90/100\n",
      "115/115 - 1s - loss: 1.9077e-04 - 1s/epoch - 13ms/step\n",
      "Epoch 91/100\n",
      "115/115 - 2s - loss: 1.8828e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 92/100\n",
      "115/115 - 1s - loss: 2.1478e-04 - 1s/epoch - 13ms/step\n",
      "Epoch 93/100\n",
      "115/115 - 1s - loss: 1.8749e-04 - 1s/epoch - 13ms/step\n",
      "Epoch 94/100\n",
      "115/115 - 2s - loss: 2.0210e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 95/100\n",
      "115/115 - 1s - loss: 1.9067e-04 - 1s/epoch - 13ms/step\n",
      "Epoch 96/100\n",
      "115/115 - 2s - loss: 1.8965e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 97/100\n",
      "115/115 - 1s - loss: 2.0907e-04 - 1s/epoch - 13ms/step\n",
      "Epoch 98/100\n",
      "115/115 - 2s - loss: 1.9114e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 99/100\n",
      "115/115 - 2s - loss: 1.8660e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 100/100\n",
      "115/115 - 2s - loss: 1.8885e-04 - 2s/epoch - 14ms/step\n",
      "11/11 [==============================] - 1s 7ms/step\n",
      "MSE: 0.0032042262429001433\n",
      "MAE: 0.0482839619962048\n",
      "R^2: 0.8180634088005763\n",
      "           Data  Valor_Real  Valor_Previsto\n",
      "4203 2020-01-21    0.981066        0.961532\n",
      "4204 2020-01-22    0.970084        0.975685\n",
      "4205 2020-01-23    0.965572        0.967532\n",
      "4206 2020-01-24    0.969603        0.962796\n",
      "4208 2020-01-28    0.974373        0.966187\n",
      "Epoch 1/100\n",
      "64/64 - 4s - loss: 0.0182 - 4s/epoch - 61ms/step\n",
      "Epoch 2/100\n",
      "64/64 - 1s - loss: 5.6895e-04 - 795ms/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "64/64 - 1s - loss: 3.7841e-04 - 786ms/epoch - 12ms/step\n",
      "Epoch 4/100\n",
      "64/64 - 1s - loss: 3.3532e-04 - 805ms/epoch - 13ms/step\n",
      "Epoch 5/100\n",
      "64/64 - 1s - loss: 3.0439e-04 - 798ms/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "64/64 - 1s - loss: 2.8807e-04 - 806ms/epoch - 13ms/step\n",
      "Epoch 7/100\n",
      "64/64 - 1s - loss: 2.7285e-04 - 865ms/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "64/64 - 1s - loss: 2.5694e-04 - 820ms/epoch - 13ms/step\n",
      "Epoch 9/100\n",
      "64/64 - 1s - loss: 3.2781e-04 - 871ms/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "64/64 - 1s - loss: 2.8205e-04 - 802ms/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "64/64 - 1s - loss: 2.4720e-04 - 815ms/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "64/64 - 1s - loss: 2.3791e-04 - 906ms/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "64/64 - 1s - loss: 2.2895e-04 - 901ms/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "64/64 - 1s - loss: 2.3141e-04 - 863ms/epoch - 13ms/step\n",
      "Epoch 15/100\n",
      "64/64 - 1s - loss: 2.5988e-04 - 894ms/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "64/64 - 1s - loss: 2.3266e-04 - 863ms/epoch - 13ms/step\n",
      "Epoch 17/100\n",
      "64/64 - 1s - loss: 2.2539e-04 - 847ms/epoch - 13ms/step\n",
      "Epoch 18/100\n",
      "64/64 - 1s - loss: 2.2394e-04 - 804ms/epoch - 13ms/step\n",
      "Epoch 19/100\n",
      "64/64 - 1s - loss: 2.7556e-04 - 759ms/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "64/64 - 1s - loss: 2.1682e-04 - 841ms/epoch - 13ms/step\n",
      "Epoch 21/100\n",
      "64/64 - 1s - loss: 2.0970e-04 - 870ms/epoch - 14ms/step\n",
      "Epoch 22/100\n",
      "64/64 - 1s - loss: 2.3269e-04 - 869ms/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "64/64 - 1s - loss: 2.0530e-04 - 770ms/epoch - 12ms/step\n",
      "Epoch 24/100\n",
      "64/64 - 1s - loss: 2.2845e-04 - 768ms/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "64/64 - 1s - loss: 3.0952e-04 - 740ms/epoch - 12ms/step\n",
      "Epoch 26/100\n",
      "64/64 - 1s - loss: 2.2595e-04 - 743ms/epoch - 12ms/step\n",
      "Epoch 27/100\n",
      "64/64 - 1s - loss: 1.9268e-04 - 752ms/epoch - 12ms/step\n",
      "Epoch 28/100\n",
      "64/64 - 1s - loss: 1.7933e-04 - 803ms/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "64/64 - 1s - loss: 1.9510e-04 - 818ms/epoch - 13ms/step\n",
      "Epoch 30/100\n",
      "64/64 - 1s - loss: 1.7565e-04 - 778ms/epoch - 12ms/step\n",
      "Epoch 31/100\n",
      "64/64 - 1s - loss: 2.2469e-04 - 827ms/epoch - 13ms/step\n",
      "Epoch 32/100\n",
      "64/64 - 1s - loss: 1.8538e-04 - 757ms/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "64/64 - 1s - loss: 1.7737e-04 - 734ms/epoch - 11ms/step\n",
      "Epoch 34/100\n",
      "64/64 - 1s - loss: 2.2332e-04 - 728ms/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "64/64 - 1s - loss: 1.8865e-04 - 743ms/epoch - 12ms/step\n",
      "Epoch 36/100\n",
      "64/64 - 1s - loss: 1.9951e-04 - 741ms/epoch - 12ms/step\n",
      "Epoch 37/100\n",
      "64/64 - 1s - loss: 2.3792e-04 - 777ms/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "64/64 - 1s - loss: 1.7701e-04 - 729ms/epoch - 11ms/step\n",
      "Epoch 39/100\n",
      "64/64 - 1s - loss: 1.7480e-04 - 751ms/epoch - 12ms/step\n",
      "Epoch 40/100\n",
      "64/64 - 1s - loss: 1.8384e-04 - 728ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "64/64 - 1s - loss: 1.5672e-04 - 727ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "64/64 - 1s - loss: 1.5271e-04 - 730ms/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "64/64 - 1s - loss: 2.0833e-04 - 743ms/epoch - 12ms/step\n",
      "Epoch 44/100\n",
      "64/64 - 1s - loss: 1.4601e-04 - 755ms/epoch - 12ms/step\n",
      "Epoch 45/100\n",
      "64/64 - 1s - loss: 1.8513e-04 - 725ms/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "64/64 - 1s - loss: 1.9808e-04 - 733ms/epoch - 11ms/step\n",
      "Epoch 47/100\n",
      "64/64 - 1s - loss: 1.5531e-04 - 726ms/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "64/64 - 1s - loss: 1.7972e-04 - 728ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "64/64 - 1s - loss: 1.8001e-04 - 723ms/epoch - 11ms/step\n",
      "Epoch 50/100\n",
      "64/64 - 1s - loss: 1.4518e-04 - 719ms/epoch - 11ms/step\n",
      "Epoch 51/100\n",
      "64/64 - 1s - loss: 1.9368e-04 - 742ms/epoch - 12ms/step\n",
      "Epoch 52/100\n",
      "64/64 - 1s - loss: 1.3563e-04 - 765ms/epoch - 12ms/step\n",
      "Epoch 53/100\n",
      "64/64 - 1s - loss: 1.5580e-04 - 756ms/epoch - 12ms/step\n",
      "Epoch 54/100\n",
      "64/64 - 1s - loss: 1.3174e-04 - 717ms/epoch - 11ms/step\n",
      "Epoch 55/100\n",
      "64/64 - 1s - loss: 1.7364e-04 - 722ms/epoch - 11ms/step\n",
      "Epoch 56/100\n",
      "64/64 - 1s - loss: 1.3967e-04 - 775ms/epoch - 12ms/step\n",
      "Epoch 57/100\n",
      "64/64 - 1s - loss: 1.2987e-04 - 768ms/epoch - 12ms/step\n",
      "Epoch 58/100\n",
      "64/64 - 1s - loss: 1.5156e-04 - 783ms/epoch - 12ms/step\n",
      "Epoch 59/100\n",
      "64/64 - 1s - loss: 1.5270e-04 - 732ms/epoch - 11ms/step\n",
      "Epoch 60/100\n",
      "64/64 - 1s - loss: 1.1653e-04 - 771ms/epoch - 12ms/step\n",
      "Epoch 61/100\n",
      "64/64 - 1s - loss: 1.4311e-04 - 728ms/epoch - 11ms/step\n",
      "Epoch 62/100\n",
      "64/64 - 1s - loss: 1.5680e-04 - 752ms/epoch - 12ms/step\n",
      "Epoch 63/100\n",
      "64/64 - 1s - loss: 1.1903e-04 - 752ms/epoch - 12ms/step\n",
      "Epoch 64/100\n",
      "64/64 - 1s - loss: 1.2954e-04 - 741ms/epoch - 12ms/step\n",
      "Epoch 65/100\n",
      "64/64 - 1s - loss: 1.5907e-04 - 731ms/epoch - 11ms/step\n",
      "Epoch 66/100\n",
      "64/64 - 1s - loss: 1.5464e-04 - 723ms/epoch - 11ms/step\n",
      "Epoch 67/100\n",
      "64/64 - 1s - loss: 1.2287e-04 - 730ms/epoch - 11ms/step\n",
      "Epoch 68/100\n",
      "64/64 - 1s - loss: 1.1163e-04 - 747ms/epoch - 12ms/step\n",
      "Epoch 69/100\n",
      "64/64 - 1s - loss: 1.3850e-04 - 737ms/epoch - 12ms/step\n",
      "Epoch 70/100\n",
      "64/64 - 1s - loss: 1.2750e-04 - 737ms/epoch - 12ms/step\n",
      "Epoch 71/100\n",
      "64/64 - 1s - loss: 1.1805e-04 - 760ms/epoch - 12ms/step\n",
      "Epoch 72/100\n",
      "64/64 - 1s - loss: 1.0674e-04 - 751ms/epoch - 12ms/step\n",
      "Epoch 73/100\n",
      "64/64 - 1s - loss: 1.1645e-04 - 797ms/epoch - 12ms/step\n",
      "Epoch 74/100\n",
      "64/64 - 1s - loss: 1.1048e-04 - 766ms/epoch - 12ms/step\n",
      "Epoch 75/100\n",
      "64/64 - 1s - loss: 1.2430e-04 - 723ms/epoch - 11ms/step\n",
      "Epoch 76/100\n",
      "64/64 - 1s - loss: 1.1520e-04 - 745ms/epoch - 12ms/step\n",
      "Epoch 77/100\n",
      "64/64 - 1s - loss: 1.2780e-04 - 797ms/epoch - 12ms/step\n",
      "Epoch 78/100\n",
      "64/64 - 1s - loss: 1.1452e-04 - 723ms/epoch - 11ms/step\n",
      "Epoch 79/100\n",
      "64/64 - 1s - loss: 1.2320e-04 - 724ms/epoch - 11ms/step\n",
      "Epoch 80/100\n",
      "64/64 - 1s - loss: 1.3204e-04 - 731ms/epoch - 11ms/step\n",
      "Epoch 81/100\n",
      "64/64 - 1s - loss: 1.1063e-04 - 719ms/epoch - 11ms/step\n",
      "Epoch 82/100\n",
      "64/64 - 1s - loss: 1.1593e-04 - 716ms/epoch - 11ms/step\n",
      "Epoch 83/100\n",
      "64/64 - 1s - loss: 1.1427e-04 - 761ms/epoch - 12ms/step\n",
      "Epoch 84/100\n",
      "64/64 - 1s - loss: 1.3775e-04 - 772ms/epoch - 12ms/step\n",
      "Epoch 85/100\n",
      "64/64 - 1s - loss: 1.1955e-04 - 765ms/epoch - 12ms/step\n",
      "Epoch 86/100\n",
      "64/64 - 1s - loss: 1.5012e-04 - 729ms/epoch - 11ms/step\n",
      "Epoch 87/100\n",
      "64/64 - 1s - loss: 1.0182e-04 - 744ms/epoch - 12ms/step\n",
      "Epoch 88/100\n",
      "64/64 - 1s - loss: 1.3592e-04 - 731ms/epoch - 11ms/step\n",
      "Epoch 89/100\n",
      "64/64 - 1s - loss: 1.2043e-04 - 718ms/epoch - 11ms/step\n",
      "Epoch 90/100\n",
      "64/64 - 1s - loss: 1.4208e-04 - 719ms/epoch - 11ms/step\n",
      "Epoch 91/100\n",
      "64/64 - 1s - loss: 1.2272e-04 - 715ms/epoch - 11ms/step\n",
      "Epoch 92/100\n",
      "64/64 - 1s - loss: 1.0943e-04 - 756ms/epoch - 12ms/step\n",
      "Epoch 93/100\n",
      "64/64 - 1s - loss: 1.2160e-04 - 776ms/epoch - 12ms/step\n",
      "Epoch 94/100\n",
      "64/64 - 1s - loss: 1.6483e-04 - 758ms/epoch - 12ms/step\n",
      "Epoch 95/100\n",
      "64/64 - 1s - loss: 1.0040e-04 - 740ms/epoch - 12ms/step\n",
      "Epoch 96/100\n",
      "64/64 - 1s - loss: 1.1205e-04 - 715ms/epoch - 11ms/step\n",
      "Epoch 97/100\n",
      "64/64 - 1s - loss: 1.0756e-04 - 711ms/epoch - 11ms/step\n",
      "Epoch 98/100\n",
      "64/64 - 1s - loss: 1.2754e-04 - 722ms/epoch - 11ms/step\n",
      "Epoch 99/100\n",
      "64/64 - 1s - loss: 1.3248e-04 - 734ms/epoch - 11ms/step\n",
      "Epoch 100/100\n",
      "64/64 - 1s - loss: 1.2096e-04 - 731ms/epoch - 11ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "MSE: 0.0009717320408526083\n",
      "MAE: 0.022397532473183848\n",
      "R^2: 0.8631555839514395\n",
      "           Data  Valor_Real  Valor_Previsto\n",
      "4205 2020-01-23    0.931164        0.928403\n",
      "4206 2020-01-24    0.935806        0.930098\n",
      "4208 2020-01-28    0.954233        0.934871\n",
      "4209 2020-01-29    0.955951        0.950413\n",
      "4210 2020-01-30    0.980087        0.954155\n",
      "Epoch 1/100\n",
      "98/98 - 4s - loss: 0.0122 - 4s/epoch - 38ms/step\n",
      "Epoch 2/100\n",
      "98/98 - 1s - loss: 0.0042 - 1s/epoch - 11ms/step\n",
      "Epoch 3/100\n",
      "98/98 - 1s - loss: 0.0043 - 1s/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "98/98 - 1s - loss: 0.0042 - 1s/epoch - 11ms/step\n",
      "Epoch 5/100\n",
      "98/98 - 1s - loss: 0.0043 - 1s/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "98/98 - 1s - loss: 0.0040 - 1s/epoch - 12ms/step\n",
      "Epoch 7/100\n",
      "98/98 - 1s - loss: 0.0042 - 1s/epoch - 13ms/step\n",
      "Epoch 8/100\n",
      "98/98 - 1s - loss: 0.0042 - 1s/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "98/98 - 1s - loss: 0.0041 - 1s/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "98/98 - 1s - loss: 0.0043 - 1s/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "98/98 - 1s - loss: 0.0040 - 1s/epoch - 12ms/step\n",
      "Epoch 12/100\n",
      "98/98 - 1s - loss: 0.0042 - 1s/epoch - 12ms/step\n",
      "Epoch 13/100\n",
      "98/98 - 1s - loss: 0.0041 - 1s/epoch - 13ms/step\n",
      "Epoch 14/100\n",
      "98/98 - 1s - loss: 0.0042 - 1s/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "98/98 - 1s - loss: 0.0042 - 1s/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "98/98 - 1s - loss: 0.0040 - 1s/epoch - 10ms/step\n",
      "Epoch 17/100\n",
      "98/98 - 1s - loss: 0.0040 - 1s/epoch - 10ms/step\n",
      "Epoch 18/100\n",
      "98/98 - 1s - loss: 0.0041 - 1s/epoch - 10ms/step\n",
      "Epoch 19/100\n",
      "98/98 - 1s - loss: 0.0041 - 1s/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "98/98 - 1s - loss: 0.0039 - 1s/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "98/98 - 1s - loss: 0.0040 - 1s/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "98/98 - 1s - loss: 0.0040 - 1s/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "98/98 - 1s - loss: 0.0038 - 1s/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "98/98 - 1s - loss: 0.0039 - 1s/epoch - 11ms/step\n",
      "Epoch 25/100\n",
      "98/98 - 1s - loss: 0.0038 - 1s/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "98/98 - 1s - loss: 0.0038 - 1s/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "98/98 - 1s - loss: 0.0038 - 1s/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "98/98 - 1s - loss: 0.0038 - 1s/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "98/98 - 1s - loss: 0.0038 - 1s/epoch - 11ms/step\n",
      "Epoch 30/100\n",
      "98/98 - 1s - loss: 0.0040 - 1s/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "98/98 - 1s - loss: 0.0037 - 1s/epoch - 12ms/step\n",
      "Epoch 32/100\n",
      "98/98 - 1s - loss: 0.0037 - 1s/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "98/98 - 1s - loss: 0.0037 - 1s/epoch - 11ms/step\n",
      "Epoch 34/100\n",
      "98/98 - 1s - loss: 0.0038 - 1s/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "98/98 - 1s - loss: 0.0037 - 1s/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "98/98 - 1s - loss: 0.0036 - 1s/epoch - 12ms/step\n",
      "Epoch 37/100\n",
      "98/98 - 1s - loss: 0.0037 - 1s/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "98/98 - 1s - loss: 0.0037 - 1s/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "98/98 - 1s - loss: 0.0038 - 1s/epoch - 12ms/step\n",
      "Epoch 40/100\n",
      "98/98 - 1s - loss: 0.0037 - 1s/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "98/98 - 1s - loss: 0.0038 - 1s/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "98/98 - 1s - loss: 0.0039 - 1s/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "98/98 - 1s - loss: 0.0037 - 1s/epoch - 12ms/step\n",
      "Epoch 44/100\n",
      "98/98 - 1s - loss: 0.0036 - 1s/epoch - 12ms/step\n",
      "Epoch 45/100\n",
      "98/98 - 1s - loss: 0.0038 - 1s/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "98/98 - 1s - loss: 0.0036 - 1s/epoch - 10ms/step\n",
      "Epoch 47/100\n",
      "98/98 - 1s - loss: 0.0037 - 1s/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "98/98 - 1s - loss: 0.0036 - 1s/epoch - 10ms/step\n",
      "Epoch 49/100\n",
      "98/98 - 1s - loss: 0.0036 - 1s/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "98/98 - 1s - loss: 0.0035 - 1s/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "98/98 - 1s - loss: 0.0036 - 1s/epoch - 10ms/step\n",
      "Epoch 52/100\n",
      "98/98 - 1s - loss: 0.0036 - 1s/epoch - 10ms/step\n",
      "Epoch 53/100\n",
      "98/98 - 1s - loss: 0.0035 - 1s/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "98/98 - 1s - loss: 0.0035 - 1s/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "98/98 - 1s - loss: 0.0035 - 1s/epoch - 10ms/step\n",
      "Epoch 56/100\n",
      "98/98 - 1s - loss: 0.0037 - 1s/epoch - 11ms/step\n",
      "Epoch 57/100\n",
      "98/98 - 1s - loss: 0.0036 - 1s/epoch - 11ms/step\n",
      "Epoch 58/100\n",
      "98/98 - 1s - loss: 0.0035 - 1s/epoch - 10ms/step\n",
      "Epoch 59/100\n",
      "98/98 - 1s - loss: 0.0034 - 1s/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "98/98 - 1s - loss: 0.0037 - 1s/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "98/98 - 1s - loss: 0.0034 - 1s/epoch - 11ms/step\n",
      "Epoch 62/100\n",
      "98/98 - 1s - loss: 0.0034 - 1s/epoch - 11ms/step\n",
      "Epoch 63/100\n",
      "98/98 - 1s - loss: 0.0035 - 1s/epoch - 10ms/step\n",
      "Epoch 64/100\n",
      "98/98 - 1s - loss: 0.0034 - 1s/epoch - 10ms/step\n",
      "Epoch 65/100\n",
      "98/98 - 1s - loss: 0.0034 - 1s/epoch - 11ms/step\n",
      "Epoch 66/100\n",
      "98/98 - 1s - loss: 0.0035 - 1s/epoch - 11ms/step\n",
      "Epoch 67/100\n",
      "98/98 - 1s - loss: 0.0034 - 1s/epoch - 11ms/step\n",
      "Epoch 68/100\n",
      "98/98 - 1s - loss: 0.0035 - 1s/epoch - 11ms/step\n",
      "Epoch 69/100\n",
      "98/98 - 1s - loss: 0.0035 - 1s/epoch - 11ms/step\n",
      "Epoch 70/100\n",
      "98/98 - 1s - loss: 0.0033 - 1s/epoch - 11ms/step\n",
      "Epoch 71/100\n",
      "98/98 - 1s - loss: 0.0034 - 1s/epoch - 11ms/step\n",
      "Epoch 72/100\n",
      "98/98 - 1s - loss: 0.0035 - 1s/epoch - 11ms/step\n",
      "Epoch 73/100\n",
      "98/98 - 1s - loss: 0.0034 - 1s/epoch - 11ms/step\n",
      "Epoch 74/100\n",
      "98/98 - 1s - loss: 0.0033 - 1s/epoch - 12ms/step\n",
      "Epoch 75/100\n",
      "98/98 - 1s - loss: 0.0033 - 1s/epoch - 11ms/step\n",
      "Epoch 76/100\n",
      "98/98 - 1s - loss: 0.0033 - 1s/epoch - 10ms/step\n",
      "Epoch 77/100\n",
      "98/98 - 1s - loss: 0.0033 - 1s/epoch - 10ms/step\n",
      "Epoch 78/100\n",
      "98/98 - 1s - loss: 0.0033 - 1s/epoch - 10ms/step\n",
      "Epoch 79/100\n",
      "98/98 - 1s - loss: 0.0034 - 1s/epoch - 10ms/step\n",
      "Epoch 80/100\n",
      "98/98 - 1s - loss: 0.0032 - 1s/epoch - 10ms/step\n",
      "Epoch 81/100\n",
      "98/98 - 1s - loss: 0.0032 - 1s/epoch - 10ms/step\n",
      "Epoch 82/100\n",
      "98/98 - 1s - loss: 0.0031 - 1s/epoch - 10ms/step\n",
      "Epoch 83/100\n",
      "98/98 - 1s - loss: 0.0032 - 1s/epoch - 10ms/step\n",
      "Epoch 84/100\n",
      "98/98 - 1s - loss: 0.0031 - 1s/epoch - 11ms/step\n",
      "Epoch 85/100\n",
      "98/98 - 1s - loss: 0.0033 - 1s/epoch - 11ms/step\n",
      "Epoch 86/100\n",
      "98/98 - 1s - loss: 0.0031 - 1s/epoch - 11ms/step\n",
      "Epoch 87/100\n",
      "98/98 - 1s - loss: 0.0031 - 1s/epoch - 11ms/step\n",
      "Epoch 88/100\n",
      "98/98 - 1s - loss: 0.0032 - 1s/epoch - 10ms/step\n",
      "Epoch 89/100\n",
      "98/98 - 1s - loss: 0.0032 - 1s/epoch - 11ms/step\n",
      "Epoch 90/100\n",
      "98/98 - 1s - loss: 0.0031 - 1s/epoch - 11ms/step\n",
      "Epoch 91/100\n",
      "98/98 - 1s - loss: 0.0031 - 1s/epoch - 12ms/step\n",
      "Epoch 92/100\n",
      "98/98 - 1s - loss: 0.0030 - 1s/epoch - 11ms/step\n",
      "Epoch 93/100\n",
      "98/98 - 1s - loss: 0.0031 - 1s/epoch - 11ms/step\n",
      "Epoch 94/100\n",
      "98/98 - 1s - loss: 0.0030 - 1s/epoch - 10ms/step\n",
      "Epoch 95/100\n",
      "98/98 - 1s - loss: 0.0030 - 1s/epoch - 11ms/step\n",
      "Epoch 96/100\n",
      "98/98 - 1s - loss: 0.0030 - 1s/epoch - 10ms/step\n",
      "Epoch 97/100\n",
      "98/98 - 1s - loss: 0.0030 - 1s/epoch - 10ms/step\n",
      "Epoch 98/100\n",
      "98/98 - 1s - loss: 0.0030 - 1s/epoch - 11ms/step\n",
      "Epoch 99/100\n",
      "98/98 - 1s - loss: 0.0029 - 1s/epoch - 11ms/step\n",
      "Epoch 100/100\n",
      "98/98 - 1s - loss: 0.0030 - 1s/epoch - 11ms/step\n",
      "12/12 [==============================] - 1s 4ms/step\n",
      "MSE: 0.010301189459981434\n",
      "MAE: 0.058771714509229966\n",
      "R^2: 0.4935548929935386\n",
      "           Data  Valor_Real  Valor_Previsto\n",
      "4203 2020-01-21    0.998488        0.950440\n",
      "4204 2020-01-22    1.010138        0.980739\n",
      "4205 2020-01-23    1.019832        0.959532\n",
      "4206 2020-01-24    1.010010        0.981164\n",
      "4208 2020-01-28    0.993821        1.000410\n",
      "Epoch 1/100\n",
      "77/77 - 4s - loss: 0.0065 - 4s/epoch - 47ms/step\n",
      "Epoch 2/100\n",
      "77/77 - 1s - loss: 3.3795e-04 - 1s/epoch - 13ms/step\n",
      "Epoch 3/100\n",
      "77/77 - 1s - loss: 2.8067e-04 - 985ms/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "77/77 - 1s - loss: 2.9865e-04 - 972ms/epoch - 13ms/step\n",
      "Epoch 5/100\n",
      "77/77 - 1s - loss: 2.3287e-04 - 947ms/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "77/77 - 1s - loss: 2.4603e-04 - 921ms/epoch - 12ms/step\n",
      "Epoch 7/100\n",
      "77/77 - 1s - loss: 2.2841e-04 - 958ms/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "77/77 - 1s - loss: 2.0830e-04 - 946ms/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "77/77 - 1s - loss: 2.0986e-04 - 943ms/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "77/77 - 1s - loss: 2.1010e-04 - 941ms/epoch - 12ms/step\n",
      "Epoch 11/100\n",
      "77/77 - 1s - loss: 1.8635e-04 - 934ms/epoch - 12ms/step\n",
      "Epoch 12/100\n",
      "77/77 - 1s - loss: 1.9506e-04 - 927ms/epoch - 12ms/step\n",
      "Epoch 13/100\n",
      "77/77 - 1s - loss: 1.7479e-04 - 925ms/epoch - 12ms/step\n",
      "Epoch 14/100\n",
      "77/77 - 1s - loss: 2.0679e-04 - 934ms/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "77/77 - 1s - loss: 1.8749e-04 - 924ms/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "77/77 - 1s - loss: 1.7054e-04 - 969ms/epoch - 13ms/step\n",
      "Epoch 17/100\n",
      "77/77 - 1s - loss: 1.9630e-04 - 946ms/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "77/77 - 1s - loss: 1.6182e-04 - 926ms/epoch - 12ms/step\n",
      "Epoch 19/100\n",
      "77/77 - 1s - loss: 2.4347e-04 - 911ms/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "77/77 - 1s - loss: 1.8585e-04 - 871ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "77/77 - 1s - loss: 1.8657e-04 - 895ms/epoch - 12ms/step\n",
      "Epoch 22/100\n",
      "77/77 - 1s - loss: 1.5362e-04 - 913ms/epoch - 12ms/step\n",
      "Epoch 23/100\n",
      "77/77 - 1s - loss: 1.7563e-04 - 887ms/epoch - 12ms/step\n",
      "Epoch 24/100\n",
      "77/77 - 1s - loss: 1.5715e-04 - 887ms/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "77/77 - 1s - loss: 1.5926e-04 - 879ms/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "77/77 - 1s - loss: 1.4785e-04 - 978ms/epoch - 13ms/step\n",
      "Epoch 27/100\n",
      "77/77 - 1s - loss: 1.6168e-04 - 902ms/epoch - 12ms/step\n",
      "Epoch 28/100\n",
      "77/77 - 1s - loss: 1.3749e-04 - 907ms/epoch - 12ms/step\n",
      "Epoch 29/100\n",
      "77/77 - 1s - loss: 1.4784e-04 - 896ms/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "77/77 - 1s - loss: 1.5267e-04 - 882ms/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "77/77 - 1s - loss: 1.5210e-04 - 878ms/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "77/77 - 1s - loss: 1.4348e-04 - 900ms/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "77/77 - 1s - loss: 1.5418e-04 - 883ms/epoch - 11ms/step\n",
      "Epoch 34/100\n",
      "77/77 - 1s - loss: 1.5886e-04 - 936ms/epoch - 12ms/step\n",
      "Epoch 35/100\n",
      "77/77 - 1s - loss: 1.4125e-04 - 926ms/epoch - 12ms/step\n",
      "Epoch 36/100\n",
      "77/77 - 1s - loss: 1.3639e-04 - 940ms/epoch - 12ms/step\n",
      "Epoch 37/100\n",
      "77/77 - 1s - loss: 1.2682e-04 - 942ms/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "77/77 - 1s - loss: 1.4100e-04 - 919ms/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "77/77 - 1s - loss: 1.2938e-04 - 900ms/epoch - 12ms/step\n",
      "Epoch 40/100\n",
      "77/77 - 1s - loss: 1.1543e-04 - 946ms/epoch - 12ms/step\n",
      "Epoch 41/100\n",
      "77/77 - 1s - loss: 1.2391e-04 - 893ms/epoch - 12ms/step\n",
      "Epoch 42/100\n",
      "77/77 - 1s - loss: 1.4175e-04 - 922ms/epoch - 12ms/step\n",
      "Epoch 43/100\n",
      "77/77 - 1s - loss: 1.1326e-04 - 927ms/epoch - 12ms/step\n",
      "Epoch 44/100\n",
      "77/77 - 1s - loss: 1.1498e-04 - 944ms/epoch - 12ms/step\n",
      "Epoch 45/100\n",
      "77/77 - 1s - loss: 1.2570e-04 - 906ms/epoch - 12ms/step\n",
      "Epoch 46/100\n",
      "77/77 - 1s - loss: 1.2696e-04 - 890ms/epoch - 12ms/step\n",
      "Epoch 47/100\n",
      "77/77 - 1s - loss: 1.2433e-04 - 883ms/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "77/77 - 1s - loss: 1.1223e-04 - 1s/epoch - 17ms/step\n",
      "Epoch 49/100\n",
      "77/77 - 1s - loss: 1.2084e-04 - 1s/epoch - 17ms/step\n",
      "Epoch 50/100\n",
      "77/77 - 1s - loss: 1.2075e-04 - 1s/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "77/77 - 1s - loss: 1.1129e-04 - 1s/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "77/77 - 1s - loss: 1.3584e-04 - 1s/epoch - 17ms/step\n",
      "Epoch 53/100\n",
      "77/77 - 1s - loss: 1.0307e-04 - 1s/epoch - 16ms/step\n",
      "Epoch 54/100\n",
      "77/77 - 1s - loss: 9.7933e-05 - 1s/epoch - 16ms/step\n",
      "Epoch 55/100\n",
      "77/77 - 1s - loss: 1.0843e-04 - 1s/epoch - 16ms/step\n",
      "Epoch 56/100\n",
      "77/77 - 1s - loss: 1.1773e-04 - 1s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "77/77 - 1s - loss: 1.2563e-04 - 1s/epoch - 16ms/step\n",
      "Epoch 58/100\n",
      "77/77 - 1s - loss: 9.8362e-05 - 1s/epoch - 16ms/step\n",
      "Epoch 59/100\n",
      "77/77 - 1s - loss: 1.2249e-04 - 1s/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "77/77 - 1s - loss: 1.5289e-04 - 1s/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "77/77 - 1s - loss: 1.1348e-04 - 1s/epoch - 16ms/step\n",
      "Epoch 62/100\n",
      "77/77 - 1s - loss: 1.3646e-04 - 1s/epoch - 17ms/step\n",
      "Epoch 63/100\n",
      "77/77 - 1s - loss: 1.0587e-04 - 1s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "77/77 - 1s - loss: 9.8671e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 65/100\n",
      "77/77 - 1s - loss: 1.3856e-04 - 1s/epoch - 17ms/step\n",
      "Epoch 66/100\n",
      "77/77 - 1s - loss: 1.1720e-04 - 1s/epoch - 16ms/step\n",
      "Epoch 67/100\n",
      "77/77 - 1s - loss: 1.1663e-04 - 1s/epoch - 17ms/step\n",
      "Epoch 68/100\n",
      "77/77 - 1s - loss: 9.6954e-05 - 1s/epoch - 16ms/step\n",
      "Epoch 69/100\n",
      "77/77 - 1s - loss: 1.1277e-04 - 1s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "77/77 - 1s - loss: 1.3031e-04 - 1s/epoch - 17ms/step\n",
      "Epoch 71/100\n",
      "77/77 - 1s - loss: 9.6974e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 72/100\n",
      "77/77 - 1s - loss: 8.9512e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 73/100\n",
      "77/77 - 1s - loss: 9.3826e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 74/100\n",
      "77/77 - 1s - loss: 1.0163e-04 - 1s/epoch - 17ms/step\n",
      "Epoch 75/100\n",
      "77/77 - 1s - loss: 9.5001e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 76/100\n",
      "77/77 - 1s - loss: 1.0857e-04 - 1s/epoch - 16ms/step\n",
      "Epoch 77/100\n",
      "77/77 - 1s - loss: 1.0962e-04 - 1s/epoch - 16ms/step\n",
      "Epoch 78/100\n",
      "77/77 - 1s - loss: 9.5633e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 79/100\n",
      "77/77 - 1s - loss: 9.8041e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 80/100\n",
      "77/77 - 1s - loss: 9.5626e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 81/100\n",
      "77/77 - 1s - loss: 9.2170e-05 - 1s/epoch - 16ms/step\n",
      "Epoch 82/100\n",
      "77/77 - 1s - loss: 9.5739e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 83/100\n",
      "77/77 - 1s - loss: 9.5322e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 84/100\n",
      "77/77 - 1s - loss: 1.1480e-04 - 1s/epoch - 17ms/step\n",
      "Epoch 85/100\n",
      "77/77 - 1s - loss: 9.3908e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 86/100\n",
      "77/77 - 1s - loss: 9.2067e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 87/100\n",
      "77/77 - 1s - loss: 1.1780e-04 - 1s/epoch - 17ms/step\n",
      "Epoch 88/100\n",
      "77/77 - 1s - loss: 9.1404e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 89/100\n",
      "77/77 - 1s - loss: 1.1191e-04 - 1s/epoch - 17ms/step\n",
      "Epoch 90/100\n",
      "77/77 - 1s - loss: 9.7114e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 91/100\n",
      "77/77 - 1s - loss: 1.0024e-04 - 1s/epoch - 17ms/step\n",
      "Epoch 92/100\n",
      "77/77 - 1s - loss: 9.9943e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 93/100\n",
      "77/77 - 1s - loss: 1.0293e-04 - 1s/epoch - 17ms/step\n",
      "Epoch 94/100\n",
      "77/77 - 1s - loss: 9.4858e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 95/100\n",
      "77/77 - 1s - loss: 9.8789e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 96/100\n",
      "77/77 - 1s - loss: 9.2851e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 97/100\n",
      "77/77 - 1s - loss: 9.1368e-05 - 1s/epoch - 17ms/step\n",
      "Epoch 98/100\n",
      "77/77 - 1s - loss: 1.1383e-04 - 1s/epoch - 17ms/step\n",
      "Epoch 99/100\n",
      "77/77 - 1s - loss: 1.1178e-04 - 1s/epoch - 17ms/step\n",
      "Epoch 100/100\n",
      "77/77 - 1s - loss: 8.9636e-05 - 1s/epoch - 17ms/step\n",
      "8/8 [==============================] - 2s 6ms/step\n",
      "MSE: 0.0009007307498363079\n",
      "MAE: 0.021083659170854526\n",
      "R^2: 0.873851593317885\n",
      "           Data  Valor_Real  Valor_Previsto\n",
      "4205 2020-01-23    0.931164        0.940374\n",
      "4206 2020-01-24    0.935806        0.942777\n",
      "4208 2020-01-28    0.954233        0.948415\n",
      "4209 2020-01-29    0.955951        0.967401\n",
      "4210 2020-01-30    0.980087        0.966366\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Carregar os dados\n",
    "file_path_dolar = 'C:/Users/milen/OneDrive/Documentos/TCC/new/sem_clima_atualizado.csv'\n",
    "data_dolar = pd.read_csv(file_path_dolar)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime\n",
    "data_dolar['Data'] = pd.to_datetime(data_dolar['Data'])\n",
    "\n",
    "# Remover a primeira linha\n",
    "data_dolar = data_dolar.iloc[1:]\n",
    "\n",
    "# Função para remover outliers\n",
    "def remove_outliers(df, column_names):\n",
    "    for column in column_names:\n",
    "        Q1 = df[column].quantile(0.20)\n",
    "        Q3 = df[column].quantile(0.80)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 0.4 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Aplicar a remoção de outliers\n",
    "numeric_columns = data_dolar.select_dtypes(include=[np.number]).columns.tolist()\n",
    "data_dolar = remove_outliers(data_dolar, numeric_columns)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_data = data_dolar[data_dolar['Data'] < pd.to_datetime(\"2020-01-01\")]\n",
    "test_data = data_dolar[data_dolar['Data'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "\n",
    "# Selecionar variáveis dependentes e independentes\n",
    "y_train = train_data['Dif_Preco_Dolar']\n",
    "X_train = train_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "y_test = test_data['Dif_Preco_Dolar']\n",
    "X_test = test_data.drop(columns=['Data', 'Pontos', 'Dif_Preco_Dolar', 'TaxaSelic', 'OperacoesSeleic', 'UltimoEUR', 'Preco_Dolar', 'Preco_Real', 'Dif_Preco_Real'])\n",
    "\n",
    "# Calcular a média para as colunas e substituir NaN pela média\n",
    "mean_values_train = X_train.mean()\n",
    "X_train.fillna(mean_values_train, inplace=True)\n",
    "mean_values_test = X_test.mean()\n",
    "X_test.fillna(mean_values_test, inplace=True)\n",
    "\n",
    "# Tratar valores não numéricos\n",
    "non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    X_train[col] = pd.to_numeric(X_train[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "    X_test[col] = pd.to_numeric(X_test[col].str.replace('.', '').str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Treinar o modelo de Random Forest\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Definindo o tamanho da janela deslizante, por exemplo, 5 dias\n",
    "tamanho_da_janela = 30\n",
    "\n",
    "# Inicializando o DataFrame de resultados\n",
    "resultados = pd.DataFrame()\n",
    "\n",
    "# Fazendo previsões em uma janela deslizante\n",
    "for i in range(0, len(test_data), tamanho_da_janela):\n",
    "    # Selecionar os dados da janela atual\n",
    "    X_test_janela = X_test.iloc[i:i+tamanho_da_janela]\n",
    "    y_test_janela = y_test.iloc[i:i+tamanho_da_janela]\n",
    "    datas_janela = test_data['Data'].iloc[i:i+tamanho_da_janela]\n",
    "\n",
    "    # Prever os valores para a janela atual\n",
    "    y_pred_janela = model.predict(X_test_janela)\n",
    "\n",
    "    # Armazenar os resultados\n",
    "    janela_resultados = pd.DataFrame({\n",
    "        'Data': datas_janela,\n",
    "        'Valor_Real': y_test_janela,\n",
    "        'Valor_Previsto': y_pred_janela\n",
    "    })\n",
    "    resultados = pd.concat([resultados, janela_resultados], ignore_index=True)\n",
    "\n",
    "# Calcular as métricas de desempenho para todo o período de teste\n",
    "mse = mean_squared_error(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "mae = mean_absolute_error(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "r2 = r2_score(resultados['Valor_Real'], resultados['Valor_Previsto'])\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R^2:\", r2)\n",
    "print(resultados.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
