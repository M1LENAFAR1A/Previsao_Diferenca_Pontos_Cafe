{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_a = pd.read_csv('C:/Users/milen/OneDrive/Documentos/TCC/Bases/preco_cafe_v2.csv')\n",
    "# Ler a base \"b\"\n",
    "base_b = pd.read_csv('C:/Users/milen/OneDrive/Documentos/TCC/Bases/clima_patrocinio_preprocessada.csv')\n",
    "# Ler a base \"c\" sem a especificação do delimitador\n",
    "base_c = pd.read_csv('C:/Users/milen/OneDrive/Documentos/TCC/Bases/ibovespa_preprocessada.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools\n",
    "\n",
    "# Load your data (replace 'base_a' with your data)\n",
    "data = base_a\n",
    "data['Data'] = pd.to_datetime(data['Data'])\n",
    "data.set_index('Data', inplace=True)\n",
    "data['Preco_Real'] = pd.to_numeric(data['Preco_Real'], errors='coerce')\n",
    "data = data.dropna(subset=['Preco_Real'])\n",
    "\n",
    "# After loading the data\n",
    "print(\"Loaded Data Shape:\", data.shape)\n",
    "print(\"First 5 Rows of Loaded Data:\\n\", data.head())\n",
    "\n",
    "# Split the data into training, test, and validation sets\n",
    "train_size = int(0.6 * len(data))\n",
    "test_size = int(0.2 * len(data))\n",
    "val_size = len(data) - train_size - test_size\n",
    "\n",
    "train_data = data.iloc[:train_size]\n",
    "test_data = data.iloc[train_size:train_size + test_size]\n",
    "val_data = data.iloc[train_size + test_size:]\n",
    "\n",
    "# After splitting the data\n",
    "print(\"Train Data Shape:\", train_data.shape)\n",
    "print(\"Test Data Shape:\", test_data.shape)\n",
    "print(\"Validation Data Shape:\", val_data.shape)\n",
    "print(\"First 5 Rows of Train Data:\\n\", train_data.head())\n",
    "print(\"First 5 Rows of Test Data:\\n\", test_data.head())\n",
    "print(\"First 5 Rows of Validation Data:\\n\", val_data.head())\n",
    "\n",
    "# Ensure train and test data have the same frequency\n",
    "assert train_data.index.freq == test_data.index.freq, \"Train and test data have different frequencies.\"\n",
    "\n",
    "# Debug the time index\n",
    "print(\"Start of Test Data:\", test_data.index[0])\n",
    "print(\"End of Test Data:\", test_data.index[-1])\n",
    "\n",
    "\n",
    "# Rest of your code for SARIMA modeling and forecasting\n",
    "\n",
    "# Define the range of p, d, and q values for both non-seasonal and seasonal components\n",
    "p_values = range(0, 3)\n",
    "d_values = range(0, 2)\n",
    "q_values = range(0, 3)\n",
    "P_values = range(0, 3)\n",
    "D_values = range(0, 2)\n",
    "Q_values = range(0, 3)\n",
    "s = 12  # Assuming monthly data with a 12-month seasonality\n",
    "\n",
    "# Create a list of all possible combinations of orders\n",
    "orders = list(itertools.product(p_values, d_values, q_values))\n",
    "seasonal_orders = list(itertools.product(P_values, D_values, Q_values, [s]))\n",
    "\n",
    "best_mse = float('inf')\n",
    "best_order = None\n",
    "best_seasonal_order = None\n",
    "\n",
    "# Iterate through all possible order combinations\n",
    "for order in orders:\n",
    "    for seasonal_order in seasonal_orders:\n",
    "        try:\n",
    "            model = SARIMAX(train_data['Preco_Real'], order=order, seasonal_order=seasonal_order)\n",
    "            results = model.fit()\n",
    "\n",
    "            # Make predictions with the test data\n",
    "            forecast = results.get_forecast(steps=len(test_data))\n",
    "            predicted = forecast.predicted_mean\n",
    "\n",
    "            # Calculate MSE\n",
    "            mse = mean_squared_error(test_data['Preco_Real'], predicted)\n",
    "\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_order = order\n",
    "                best_seasonal_order = seasonal_order\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# Print the best SARIMA orders and MSE\n",
    "print(\"Best SARIMA Order:\", best_order)\n",
    "print(\"Best SARIMA Seasonal Order:\", best_seasonal_order)\n",
    "print(\"Best MSE:\", best_mse)\n",
    "\n",
    "# Now, fit the SARIMA model with the best orders\n",
    "model = SARIMAX(train_data['Preco_Real'], order=best_order, seasonal_order=best_seasonal_order)\n",
    "results = model.fit()\n",
    "\n",
    "# Make predictions with the test data\n",
    "forecast = results.get_forecast(steps=len(test_data))\n",
    "predicted = forecast.predicted_mean\n",
    "\n",
    "# Calculate the MSE with test data\n",
    "mse = mean_squared_error(test_data['Preco_Real'], predicted)\n",
    "print(\"MSE with Test Data:\", mse)\n",
    "\n",
    "# Make predictions with the validation data\n",
    "forecast_val = results.get_forecast(steps=len(val_data))\n",
    "predicted_val = forecast_val.predicted_mean\n",
    "\n",
    "# Calculate the MSE with validation data\n",
    "mse_val = mean_squared_error(val_data['Preco_Real'], predicted_val)\n",
    "print(\"MSE with Validation Data:\", mse_val)\n",
    "\n",
    "# Plot the predictions with test and validation data\n",
    "forecast_ci = forecast.conf_int()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_data['Preco_Real'], label='Training')\n",
    "plt.plot(test_data['Preco_Real'], label='Test')\n",
    "plt.plot(val_data.index, predicted_val, label='Validation', color='orange')\n",
    "plt.fill_between(forecast_ci.index, forecast_ci.iloc[:, 0], forecast_ci.iloc[:, 1], color='pink')\n",
    "plt.title('SARIMA Forecast with Test and Validation Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Real Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Carregar os dados\n",
    "data = base_a\n",
    "data['Data'] = pd.to_datetime(data['Data'])\n",
    "data.set_index('Data', inplace=True)\n",
    "data['Preco_Real'] = pd.to_numeric(data['Preco_Real'], errors='coerce')\n",
    "data = data.dropna(subset=['Preco_Real'])\n",
    "\n",
    "# Explorar os dados\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data['Preco_Real'])\n",
    "plt.title('Preço Real ao Longo do Tempo')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço Real')\n",
    "plt.show()\n",
    "\n",
    "# Dividir os dados em treinamento, teste e validação\n",
    "train_size = int(0.7 * len(data))\n",
    "test_size = int(0.2 * len(data))\n",
    "train_data = data.iloc[:train_size]\n",
    "test_data = data.iloc[train_size:train_size+test_size]\n",
    "val_data = data.iloc[train_size+test_size:]\n",
    "\n",
    "# Identificar ordens do modelo SARIMA\n",
    "order = (1, 1, 1)  # Substitua pelas ordens adequadas (p, d, q)\n",
    "seasonal_order = (1, 1, 1, 12)  # Substitua pelas ordens adequadas (P, D, Q, S)\n",
    "\n",
    "# Ajustar o modelo SARIMA com os dados de treinamento\n",
    "model = SARIMAX(train_data['Preco_Real'], order=order, seasonal_order=seasonal_order)\n",
    "results = model.fit()\n",
    "\n",
    "# Fazer previsões com os dados de teste\n",
    "forecast = results.get_forecast(steps=len(test_data))\n",
    "\n",
    "# Intervalo de confiança\n",
    "forecast_ci = forecast.conf_int()\n",
    "\n",
    "# Plotar previsões com os dados de teste\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_data['Preco_Real'], label='Treinamento')\n",
    "plt.plot(test_data['Preco_Real'], label='Teste')\n",
    "plt.plot(forecast.predicted_mean, label='Previsão', color='r')\n",
    "plt.fill_between(forecast_ci.index, forecast_ci.iloc[:, 0], forecast_ci.iloc[:, 1], color='pink')\n",
    "plt.title('Previsão SARIMA com Dados de Teste')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço Real')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Dados reais e previsões com dados de teste\n",
    "observed = test_data['Preco_Real']\n",
    "predicted = forecast.predicted_mean\n",
    "\n",
    "# Calcular o erro quadrático médio (MSE) com dados de teste\n",
    "mse = mean_squared_error(observed, predicted)\n",
    "print(\"Erro Quadrático Médio (MSE) com Dados de Teste:\", mse)\n",
    "\n",
    "# Fazer previsões com os dados de validação\n",
    "forecast_val = results.get_forecast(steps=len(val_data))\n",
    "\n",
    "# Calcular o erro quadrático médio (MSE) com dados de validação\n",
    "observed_val = val_data['Preco_Real']\n",
    "predicted_val = forecast_val.predicted_mean\n",
    "mse_val = mean_squared_error(observed_val, predicted_val)\n",
    "print(\"Erro Quadrático Médio (MSE) com Dados de Validação:\", mse_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Exemplo de dados das paradas\n",
    "paradas = [\n",
    "    {\n",
    "        \"cp\": 340015329,\n",
    "        \"np\": \"AFONSO BRAZ B/C1\",\n",
    "        \"ed\": \"R ARMINDA/ R BALTHAZAR DA VEIGA\",\n",
    "        \"py\": -23.592938,\n",
    "        \"px\": -46.672727\n",
    "    },\n",
    "    # Adicione mais paradas conforme necessário\n",
    "]\n",
    "\n",
    "# Função para verificar o token de autorização\n",
    "def verificar_token(token):\n",
    "    # Implemente a lógica para verificar se o token é válido aqui\n",
    "    return token == \"2800bba5141feb67b2d3bafc8145c1c962ca1c208bac36075b4f889e8513e8bf\"  # Substitua com o seu token real\n",
    "\n",
    "@app.route('/Parada/BuscarParadasPorLinha', methods=['GET'])\n",
    "def buscar_paradas_por_linha():\n",
    "    codigo_linha = request.args.get('codigoLinha')\n",
    "    \n",
    "    # Obtenha o token de autorização do cabeçalho da solicitação\n",
    "    token = request.headers.get('Authorization')\n",
    "\n",
    "    # Verifique se o token é válido\n",
    "    if not token or not verificar_token(token):\n",
    "        return jsonify({\"error\": \"Token de autorização inválido\"}), 401\n",
    "\n",
    "    # Aqui você pode implementar a lógica para buscar paradas com base no código da linha\n",
    "    # Neste exemplo, estamos retornando todas as paradas, mas você pode filtrar com base no código da linha.\n",
    "    paradas_filtradas = paradas\n",
    "\n",
    "    return jsonify(paradas_filtradas)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Seus dados\n",
    "data = pd.read_csv('C:/Users/milen/OneDrive/Documentos/TCC/Bases/preco_cafe_preprocessada.csv')\n",
    "\n",
    "# Transforme os dados em um DataFrame\n",
    "data = [line.split(',') for line in data.split('\\n')]\n",
    "df = pd.DataFrame(data, columns=['Data', 'Preco_Real', 'Preco_Dolar'])\n",
    "df['Data'] = pd.to_datetime(df['Data'])\n",
    "\n",
    "# Separar as variáveis independentes (X) e dependentes (y)\n",
    "X = df[['Preco_Real']]\n",
    "y = df['Preco_Dolar']\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar e treinar o modelo de regressão linear\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões com o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliar a precisão do modelo (você pode usar outras métricas)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Erro quadrático médio (MSE):\", mse)\n",
    "print(\"Coeficiente de determinação (R²):\", r2)\n",
    "\n",
    "# Visualizar os resultados\n",
    "plt.scatter(X_test, y_test, color='blue')\n",
    "plt.plot(X_test, y_pred, color='red', linewidth=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Carregue os dados\n",
    "data = base_a  # Substitua 'seu_arquivo.csv' pelo nome do seu arquivo\n",
    "data['Data'] = pd.to_datetime(data['Data'])\n",
    "data['Preco_Real'] = data['Preco_Real'].str.replace('.', '', regex=False).str.replace(',', '.').astype(float)\n",
    "\n",
    "\n",
    "# Divida os dados em recursos (X) e rótulos (y)\n",
    "X = data[['Preco_Real', 'Preco_Dolar']]\n",
    "y = data['Preco_Real']\n",
    "\n",
    "# Divida os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalização dos dados\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Crie o modelo\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(2,)),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile o modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Treine o modelo\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Avalie o modelo\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}')\n",
    "\n",
    "# Faça previsões\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calcule a precisão do modelo (por exemplo, erro médio absoluto)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(f'Mean Absolute Error: {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Carregar os dados\n",
    "data = base_a  # Substitua 'seu_arquivo.csv' pelo nome do seu arquivo CSV\n",
    "\n",
    "# Pré-processar os dados\n",
    "data['Data'] = pd.to_datetime(data['Data'])\n",
    "data['Preco_Real'] = data['Preco_Real'].str.replace('.', '', regex=False).str.replace(',', '.').astype(float)\n",
    "\n",
    "# Ensure data is sorted by date\n",
    "data = data.sort_values(by='Data')\n",
    "\n",
    "# Resample data to monthly frequency and handle any missing or irregular dates\n",
    "data.set_index('Data', inplace=True)\n",
    "data = data.resample('M').mean()  # Assuming you want to take the mean for the month\n",
    "\n",
    "# Check if there are any missing dates\n",
    "missing_dates = pd.date_range(start=data.index.min(), end=data.index.max(), freq='M').difference(data.index)\n",
    "if not missing_dates.empty:\n",
    "    print(f\"Missing dates: {missing_dates}\")\n",
    "\n",
    "# Set the frequency to 'M' for monthly data\n",
    "data.index.freq = 'M'\n",
    "\n",
    "# Identificar ordens do modelo SARIMA\n",
    "order = (1, 1, 1)  # Substitua pelas ordens adequadas (p, d, q)\n",
    "seasonal_order = (1, 1, 1, 12)  # Substitua pelas ordens adequadas (P, D, Q, S)\n",
    "\n",
    "# Ajustar o modelo SARIMA\n",
    "model = SARIMAX(data['Preco_Real'], order=order, seasonal_order=seasonal_order)\n",
    "results = model.fit()\n",
    "\n",
    "# Fazer previsões para 2023\n",
    "forecast_steps = 12  # Número de etapas à frente para prever\n",
    "forecast = results.get_forecast(steps=forecast_steps)\n",
    "\n",
    "# Obter as primeiras 5 observações de 2023 to match the length of available data\n",
    "obs_2023 = data['Preco_Real']['2023-01-01':'2023-05-01']\n",
    "\n",
    "# Calcular o MSE apenas para as observações de 2023\n",
    "mse = mean_squared_error(obs_2023, forecast.predicted_mean[:4])  # Adjust the index to match the available data\n",
    "\n",
    "# Calcular o MAPE\n",
    "actual = obs_2023\n",
    "predicted = forecast.predicted_mean[:4]  # Adjust the index to match the available data\n",
    "mape = np.mean(np.abs((actual - predicted) / actual.astype(float)) * 100)\n",
    "mae = mean_absolute_error(obs_2023, forecast.predicted_mean[:5])  # Adjust the index to match the available data\n",
    "# Criar um índice de datas para o intervalo de previsões\n",
    "forecast_index = pd.date_range(start='2023-01-01', periods=forecast_steps, freq='M')\n",
    "\n",
    "# Extract lower and upper bounds of the confidence interval using the forecast object\n",
    "confidence_interval = forecast.conf_int()\n",
    "\n",
    "# Filter confidence interval for the specific dates\n",
    "lower_bound = confidence_interval.loc['2023-01-01':'2023-05-01', 'lower Preco_Real']\n",
    "upper_bound = confidence_interval.loc['2023-01-01':'2023-05-01', 'upper Preco_Real']\n",
    "\n",
    "# Create a range of dates for plotting (forecast_index)\n",
    "forecast_index = pd.date_range(start='2023-01-01', periods=forecast_steps, freq='M')\n",
    "\n",
    "# Check if lower_bound and upper_bound have the same shape and are not empty\n",
    "if not (lower_bound.empty or upper_bound.empty) and len(lower_bound) == forecast_steps and len(upper_bound) == forecast_steps:\n",
    "    # Plotar os dados originais e as previsões com intervalo de confiança\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(data.index, data['Preco_Real'], label='Dados Originais', linewidth=2)\n",
    "    plt.plot(forecast_index, forecast.predicted_mean, label='Previsão', color='red', linestyle='--', linewidth=2)\n",
    "    plt.fill_between(forecast_index, lower_bound, upper_bound, color='pink', alpha=0.3)\n",
    "    plt.title('Previsão de Preço Real para 2023')\n",
    "    plt.xlabel('Data')\n",
    "    plt.ylabel('Preço Real')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No valid confidence interval data for the specified forecast dates.\")\n",
    "\n",
    "\n",
    "print(f\"Erro Quadrático Médio (MSE) para 2023: {mse:.2f}\")\n",
    "print(f\"Erro Quadrático Médio Percentual (MAPE) para 2023: {mape:.2f}%\")\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE) for 2023: {mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Carregar os dados\n",
    "data = base_a\n",
    "data['Data'] = pd.to_datetime(data['Data'])\n",
    "data.set_index('Data', inplace=True)\n",
    "data['Preco_Real'] = pd.to_numeric(data['Preco_Real'], errors='coerce')\n",
    "data = data.dropna(subset=['Preco_Real'])\n",
    "\n",
    "# Explorar os dados\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data['Preco_Real'])\n",
    "plt.title('Preço Real ao Longo do Tempo')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço Real')\n",
    "plt.show()\n",
    "\n",
    "# Identificar ordens do modelo SARIMA\n",
    "order = (1, 1, 1)  # Substitua pelas ordens adequadas (p, d, q)\n",
    "seasonal_order = (1, 1, 1, 12)  # Substitua pelas ordens adequadas (P, D, Q, S)\n",
    "\n",
    "# Ajustar o modelo SARIMA\n",
    "model = SARIMAX(data['Preco_Real'], order=order, seasonal_order=seasonal_order)\n",
    "results = model.fit()\n",
    "\n",
    "# Fazer previsões\n",
    "forecast = results.get_forecast(steps=30)  # Substitua 30 pelo número de passos que você deseja prever\n",
    "\n",
    "# Intervalo de confiança\n",
    "forecast_ci = forecast.conf_int()\n",
    "\n",
    "# Plotar previsões\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data['Preco_Real'], label='Observado')\n",
    "plt.plot(forecast.predicted_mean, label='Previsão', color='r')\n",
    "plt.fill_between(forecast_ci.index, forecast_ci.iloc[:, 0], forecast_ci.iloc[:, 1], color='pink')\n",
    "plt.title('Previsão SARIMA')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço Real')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Dados reais\n",
    "observed = data['Preco_Real']\n",
    "\n",
    "# Previsões\n",
    "predicted = forecast.predicted_mean\n",
    "\n",
    "# Calcular o erro quadrático médio (MSE)\n",
    "mse = mean_squared_error(observed, predicted)\n",
    "print(\"Erro Quadrático Médio (MSE):\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Carregar os dados\n",
    "data = base_a\n",
    "data['Data'] = pd.to_datetime(data['Data'])\n",
    "data['Data'] = data['Data'].dt.to_period('D')  # Define a frequência como diária (ou ajuste para a frequência dos seus dados)\n",
    "data['Preco_Real'] = data['Preco_Real'].str.replace('.', '').str.replace(',', '.').astype(float)\n",
    "\n",
    "# Definir o índice como a coluna 'Data'\n",
    "data.set_index('Data', inplace=True)\n",
    "\n",
    "# Converter o objeto 'Period' de volta para float\n",
    "data['Preco_Real'] = data['Preco_Real'].astype(float)\n",
    "\n",
    "# Explorar os dados\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data['Preco_Real'])\n",
    "plt.title('Preço Real ao Longo do Tempo')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço Real')\n",
    "plt.show()\n",
    "\n",
    "# Decompor a série temporal\n",
    "decomposition = sm.tsa.seasonal_decompose(data['Preco_Real'], model='additive')\n",
    "fig = decomposition.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Identificar ordens do modelo SARIMA\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(211)\n",
    "plot_acf(data['Preco_Real'], ax=plt.gca(), lags=40)\n",
    "plt.subplot(212)\n",
    "plot_pacf(data['Preco_Real'], ax=plt.gca(), lags=40)\n",
    "plt.show()\n",
    "\n",
    "# Ajustar o modelo SARIMA\n",
    "# Substitua as ordens apropriadas (p, d, q, P, D, Q, S) com base na análise dos gráficos ACF e PACF\n",
    "order = (p, d, q)\n",
    "seasonal_order = (P, D, Q, S)\n",
    "\n",
    "model = sm.tsa.SARIMAX(data['Preco_Real'], order=order, seasonal_order=seasonal_order)\n",
    "results = model.fit()\n",
    "\n",
    "# Fazer previsões\n",
    "forecast = results.get_forecast(steps=30)  # Substitua 30 pelo número de passos que você deseja prever\n",
    "\n",
    "# Intervalo de confiança\n",
    "forecast_ci = forecast.conf_int()\n",
    "\n",
    "# Plotar previsões\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data['Preco_Real'], label='Observado')\n",
    "plt.plot(forecast.predicted_mean, label='Previsão', color='r')\n",
    "plt.fill_between(forecast_ci.index, forecast_ci.iloc[:, 0], forecast_ci.iloc[:, 1], color='pink')\n",
    "plt.title('Previsão SARIMA')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço Real')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
